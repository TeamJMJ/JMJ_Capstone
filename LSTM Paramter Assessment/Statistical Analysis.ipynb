{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a02b55",
   "metadata": {},
   "source": [
    "# University of Michigan \n",
    "# Master of Applied Data Science\n",
    "### SIAD 699: Capstone\n",
    "Team: James Yoon (jamyoon), Mario Feliciano (felicma), and James Tuccori (jtuccori)\n",
    "\n",
    "Date: April 2023\n",
    "____\n",
    "# Social Media Sentiment & Predicting Trading Signals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd5212",
   "metadata": {},
   "source": [
    "#### The purpose of this notebook is to assess all the different paramters for the LSTM model to be able to see the best paramters to select. Our assessment and logic for selecting Timestep: 12 ; Neurons: 128; Dropout: 0.1,  Learning: 0.001; With a difference of 0.001687132, LSTM Acc. AVG of 0.530923147, and Val Acc.AVG of 0.529236015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8026198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da0abe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "a1 = pd.read_csv('LSTM Paramter Assessment/AnalysisConsolidates testingresultsJTGraph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42aaacf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'LSTM_Acc_AVG', 'Val_Acc_AVG', 'Timestep', 'Neurons',\n",
       "       'Dropout', 'Learning', 'difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a70fe868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_Acc_AVG</th>\n",
       "      <th>Val_Acc_AVG</th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.514168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529273</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517909</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528545</td>\n",
       "      <td>0.520268</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520773</td>\n",
       "      <td>0.515682</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.525217</td>\n",
       "      <td>0.526243</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.508984</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.524989</td>\n",
       "      <td>0.524549</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.507336</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.527057</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LSTM_Acc_AVG  Val_Acc_AVG  Timestep  Neurons  Dropout  Learning  \\\n",
       "0        0.520318     0.514168         2        2      0.1     0.010   \n",
       "1        0.529273     0.522300         2        2      0.1     0.001   \n",
       "2        0.517909     0.512745         2        2      0.2     0.010   \n",
       "3        0.528545     0.520268         2        2      0.2     0.001   \n",
       "4        0.520773     0.515682         2        2      0.3     0.010   \n",
       "..            ...          ...       ...      ...      ...       ...   \n",
       "220      0.525217     0.526243       168      128      0.2     0.001   \n",
       "221      0.517208     0.508984       168      128      0.3     0.010   \n",
       "222      0.524989     0.524549       168      128      0.3     0.001   \n",
       "223      0.505767     0.507336       168      128      0.4     0.010   \n",
       "224      0.526911     0.527057       168      128      0.4     0.001   \n",
       "\n",
       "     difference  \n",
       "0      0.006150  \n",
       "1      0.006973  \n",
       "2      0.005164  \n",
       "3      0.008277  \n",
       "4      0.005091  \n",
       "..          ...  \n",
       "220   -0.001025  \n",
       "221    0.008224  \n",
       "222    0.000439  \n",
       "223   -0.001570  \n",
       "224   -0.000146  \n",
       "\n",
       "[225 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = a1[['LSTM_Acc_AVG', 'Val_Acc_AVG', 'Timestep', 'Neurons',\n",
    "       'Dropout', 'Learning', 'difference']]\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19613505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LSTM_Acc_AVG', 'Val_Acc_AVG', 'Timestep', 'Neurons', 'Dropout',\n",
       "       'Learning', 'difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "375bb7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.506023033885689e-05\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           LSTM_Acc_AVG   R-squared:                       0.016\n",
      "Model:                            OLS   Adj. R-squared:                  0.012\n",
      "Method:                 Least Squares   F-statistic:                     3.739\n",
      "Date:                Sun, 19 Mar 2023   Prob (F-statistic):             0.0544\n",
      "Time:                        13:30:51   Log-Likelihood:                 792.73\n",
      "No. Observations:                 225   AIC:                            -1581.\n",
      "Df Residuals:                     223   BIC:                            -1575.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5260      0.001    804.215      0.000       0.525       0.527\n",
      "Timestep   -1.506e-05   7.79e-06     -1.934      0.054   -3.04e-05    2.89e-07\n",
      "==============================================================================\n",
      "Omnibus:                       44.559   Durbin-Watson:                   2.188\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               66.078\n",
      "Skew:                          -1.166   Prob(JB):                     4.48e-15\n",
      "Kurtosis:                       4.270   Cond. No.                         115.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "m1 = smf.ols(formula = 'LSTM_Acc_AVG ~Timestep',  data = a1).fit()\n",
    "reg_q2_1 = m1\n",
    "model_summary= reg_q2_1.summary()\n",
    "a1_q2_ate = reg_q2_1.params[1]\n",
    "print(a1_q2_ate)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d71dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5431066461557058e-05\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           LSTM_Acc_AVG   R-squared:                       0.279\n",
      "Model:                            OLS   Adj. R-squared:                  0.266\n",
      "Method:                 Least Squares   F-statistic:                     21.27\n",
      "Date:                Sun, 19 Mar 2023   Prob (F-statistic):           7.62e-15\n",
      "Time:                        13:30:47   Log-Likelihood:                 827.64\n",
      "No. Observations:                 225   AIC:                            -1645.\n",
      "Df Residuals:                     220   BIC:                            -1628.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5346      0.001    419.230      0.000       0.532       0.537\n",
      "Timestep   -1.543e-05   6.72e-06     -2.297      0.023   -2.87e-05   -2.19e-06\n",
      "Neurons    -2.701e-05   8.96e-06     -3.016      0.003   -4.47e-05   -9.36e-06\n",
      "Dropout       -0.0133      0.004     -3.622      0.000      -0.021      -0.006\n",
      "Learning      -0.6939      0.092     -7.576      0.000      -0.874      -0.513\n",
      "==============================================================================\n",
      "Omnibus:                       18.448   Durbin-Watson:                   1.977\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.610\n",
      "Skew:                          -0.727   Prob(JB):                     3.35e-05\n",
      "Kurtosis:                       3.288   Cond. No.                     2.10e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.1e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "m1 = smf.ols(formula = 'LSTM_Acc_AVG ~Timestep + Neurons + Dropout + Learning ',  data = a1).fit()\n",
    "reg_q2_1 = m1\n",
    "model_summary= reg_q2_1.summary()\n",
    "a1_q2_ate = reg_q2_1.params[1]\n",
    "print(a1_q2_ate)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "776013b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_Acc_AVG</th>\n",
       "      <th>Val_Acc_AVG</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning</th>\n",
       "      <th>difference</th>\n",
       "      <th>Timestep_2</th>\n",
       "      <th>Timestep_6</th>\n",
       "      <th>Timestep_12</th>\n",
       "      <th>Timestep_48</th>\n",
       "      <th>Timestep_96</th>\n",
       "      <th>Timestep_168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.514168</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529273</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517909</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528545</td>\n",
       "      <td>0.520268</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520773</td>\n",
       "      <td>0.515682</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.525217</td>\n",
       "      <td>0.526243</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.508984</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.524989</td>\n",
       "      <td>0.524549</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.507336</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.001570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.527057</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LSTM_Acc_AVG  Val_Acc_AVG  Neurons  Dropout  Learning  difference  \\\n",
       "0        0.520318     0.514168        2      0.1     0.010    0.006150   \n",
       "1        0.529273     0.522300        2      0.1     0.001    0.006973   \n",
       "2        0.517909     0.512745        2      0.2     0.010    0.005164   \n",
       "3        0.528545     0.520268        2      0.2     0.001    0.008277   \n",
       "4        0.520773     0.515682        2      0.3     0.010    0.005091   \n",
       "..            ...          ...      ...      ...       ...         ...   \n",
       "220      0.525217     0.526243      128      0.2     0.001   -0.001025   \n",
       "221      0.517208     0.508984      128      0.3     0.010    0.008224   \n",
       "222      0.524989     0.524549      128      0.3     0.001    0.000439   \n",
       "223      0.505767     0.507336      128      0.4     0.010   -0.001570   \n",
       "224      0.526911     0.527057      128      0.4     0.001   -0.000146   \n",
       "\n",
       "     Timestep_2  Timestep_6  Timestep_12  Timestep_48  Timestep_96  \\\n",
       "0             1           0            0            0            0   \n",
       "1             1           0            0            0            0   \n",
       "2             1           0            0            0            0   \n",
       "3             1           0            0            0            0   \n",
       "4             1           0            0            0            0   \n",
       "..          ...         ...          ...          ...          ...   \n",
       "220           0           0            0            0            0   \n",
       "221           0           0            0            0            0   \n",
       "222           0           0            0            0            0   \n",
       "223           0           0            0            0            0   \n",
       "224           0           0            0            0            0   \n",
       "\n",
       "     Timestep_168  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "220             1  \n",
       "221             1  \n",
       "222             1  \n",
       "223             1  \n",
       "224             1  \n",
       "\n",
       "[225 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating Dummy Values(columns) to see which timestep value is significant\n",
    "df = pd.get_dummies(a1, columns=['Timestep'], prefix='Timestep')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf2383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "442c7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07584329618723859\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           LSTM_Acc_AVG   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.8712\n",
      "Date:                Sun, 19 Mar 2023   Prob (F-statistic):              0.501\n",
      "Time:                        13:34:39   Log-Likelihood:                 793.07\n",
      "No. Observations:                 225   AIC:                            -1574.\n",
      "Df Residuals:                     219   BIC:                            -1554.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        0.4502      0.000   1084.047      0.000       0.449       0.451\n",
      "Timestep_2       0.0758      0.001     72.162      0.000       0.074       0.078\n",
      "Timestep_6       0.0753      0.001     71.662      0.000       0.073       0.077\n",
      "Timestep_12      0.0764      0.001     66.073      0.000       0.074       0.079\n",
      "Timestep_48      0.0751      0.001     64.947      0.000       0.073       0.077\n",
      "Timestep_96      0.0740      0.001     71.117      0.000       0.072       0.076\n",
      "Timestep_168     0.0735      0.001     69.958      0.000       0.071       0.076\n",
      "==============================================================================\n",
      "Omnibus:                       46.543   Durbin-Watson:                   2.194\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               71.024\n",
      "Skew:                          -1.190   Prob(JB):                     3.78e-16\n",
      "Kurtosis:                       4.384   Cond. No.                     1.42e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.3e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "m1 = smf.ols(formula = 'LSTM_Acc_AVG ~ Timestep_2 + Timestep_6 + Timestep_12 + Timestep_48 + Timestep_96 + Timestep_168',  data = df).fit()\n",
    "reg_q2_1 = m1\n",
    "model_summary= reg_q2_1.summary()\n",
    "a1_q2_ate = reg_q2_1.params[1]\n",
    "print(a1_q2_ate)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All values are significant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc4dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbbb34e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_Acc_AVG</th>\n",
       "      <th>Val_Acc_AVG</th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.514168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529273</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517909</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528545</td>\n",
       "      <td>0.520268</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520773</td>\n",
       "      <td>0.515682</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.525217</td>\n",
       "      <td>0.526243</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.508984</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.524989</td>\n",
       "      <td>0.524549</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.507336</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.527057</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LSTM_Acc_AVG  Val_Acc_AVG  Timestep  Neurons  Dropout  Learning  \\\n",
       "0        0.520318     0.514168         2        2      0.1     0.010   \n",
       "1        0.529273     0.522300         2        2      0.1     0.001   \n",
       "2        0.517909     0.512745         2        2      0.2     0.010   \n",
       "3        0.528545     0.520268         2        2      0.2     0.001   \n",
       "4        0.520773     0.515682         2        2      0.3     0.010   \n",
       "..            ...          ...       ...      ...      ...       ...   \n",
       "220      0.525217     0.526243       168      128      0.2     0.001   \n",
       "221      0.517208     0.508984       168      128      0.3     0.010   \n",
       "222      0.524989     0.524549       168      128      0.3     0.001   \n",
       "223      0.505767     0.507336       168      128      0.4     0.010   \n",
       "224      0.526911     0.527057       168      128      0.4     0.001   \n",
       "\n",
       "     difference  \n",
       "0      0.006150  \n",
       "1      0.006973  \n",
       "2      0.005164  \n",
       "3      0.008277  \n",
       "4      0.005091  \n",
       "..          ...  \n",
       "220   -0.001025  \n",
       "221    0.008224  \n",
       "222    0.000439  \n",
       "223   -0.001570  \n",
       "224   -0.000146  \n",
       "\n",
       "[225 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grouping by the values by the mean values\n",
    "\n",
    "a2 = a1.copy()\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1feb101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_Acc_AVG</th>\n",
       "      <th>Val_Acc_AVG</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.526040</td>\n",
       "      <td>0.520271</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.005769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.525515</td>\n",
       "      <td>0.520008</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.005507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.526616</td>\n",
       "      <td>0.521006</td>\n",
       "      <td>58.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.005610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.525313</td>\n",
       "      <td>0.521021</td>\n",
       "      <td>58.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.524169</td>\n",
       "      <td>0.518698</td>\n",
       "      <td>47.439024</td>\n",
       "      <td>0.253659</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>0.005471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.523723</td>\n",
       "      <td>0.519104</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.004619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LSTM_Acc_AVG  Val_Acc_AVG    Neurons   Dropout  Learning  difference\n",
       "Timestep                                                                      \n",
       "2             0.526040     0.520271  47.000000  0.250000   0.00550    0.005769\n",
       "6             0.525515     0.520008  47.000000  0.250000   0.00550    0.005507\n",
       "12            0.526616     0.521006  58.250000  0.250000   0.00550    0.005610\n",
       "48            0.525313     0.521021  58.250000  0.250000   0.00550    0.004292\n",
       "96            0.524169     0.518698  47.439024  0.253659   0.00561    0.005471\n",
       "168           0.523723     0.519104  47.000000  0.250000   0.00550    0.004619"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.groupby('Timestep').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c12ed0",
   "metadata": {},
   "source": [
    "#### To test if the LSTM_Acc_AVG values of each timestep are significantly different,\n",
    "#### we perform an Analysis of Variance (ANOVA) using the statsmodels library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da59d19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sum_sq     df        F    PR(>F)\n",
      "C(Timestep)  0.000227    5.0  0.87122  0.501193\n",
      "Residual     0.011432  219.0      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Replace 'data' with the name of your DataFrame\n",
    "model = ols('LSTM_Acc_AVG ~ C(Timestep)', data=a2).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bb654",
   "metadata": {},
   "source": [
    "####  In this case, the p-value (PR(>F)) is 0.501193, which is greater than the common significance threshold of 0.05. This means that we fail to reject the null hypothesis, suggesting that there is no significant difference between the LSTM_Acc_AVG values of each timestep. In other words, the differencesin LSTM_Acc_AVG values across the timesteps may be due to random chance rather than being an  actual effect of the timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6256b3",
   "metadata": {},
   "source": [
    "#### So to choose the best parameters for our model, we took the combination of hyperparameters that leads to the highest validation accuracy (Val_Acc_AVG) while maintaining a small difference between training and validation accuracy to avoid overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b1d02e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_Acc_AVG</th>\n",
       "      <th>Val_Acc_AVG</th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.514168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529273</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517909</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528545</td>\n",
       "      <td>0.520268</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520773</td>\n",
       "      <td>0.515682</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.525217</td>\n",
       "      <td>0.526243</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.508984</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.524989</td>\n",
       "      <td>0.524549</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.507336</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.527057</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LSTM_Acc_AVG  Val_Acc_AVG  Timestep  Neurons  Dropout  Learning  \\\n",
       "0        0.520318     0.514168         2        2      0.1     0.010   \n",
       "1        0.529273     0.522300         2        2      0.1     0.001   \n",
       "2        0.517909     0.512745         2        2      0.2     0.010   \n",
       "3        0.528545     0.520268         2        2      0.2     0.001   \n",
       "4        0.520773     0.515682         2        2      0.3     0.010   \n",
       "..            ...          ...       ...      ...      ...       ...   \n",
       "220      0.525217     0.526243       168      128      0.2     0.001   \n",
       "221      0.517208     0.508984       168      128      0.3     0.010   \n",
       "222      0.524989     0.524549       168      128      0.3     0.001   \n",
       "223      0.505767     0.507336       168      128      0.4     0.010   \n",
       "224      0.526911     0.527057       168      128      0.4     0.001   \n",
       "\n",
       "     difference  \n",
       "0      0.006150  \n",
       "1      0.006973  \n",
       "2      0.005164  \n",
       "3      0.008277  \n",
       "4      0.005091  \n",
       "..          ...  \n",
       "220   -0.001025  \n",
       "221    0.008224  \n",
       "222    0.000439  \n",
       "223   -0.001570  \n",
       "224   -0.000146  \n",
       "\n",
       "[225 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 = a1.copy()\n",
    "a3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d477ce3",
   "metadata": {},
   "source": [
    "#### We sort the  data table by Val_Acc_AVG in descending order and then look for the combinations that have the highest Val_Acc_AVG along with a relatively low difference between LSTM_Acc_AVG and Val_Acc_AVG (the \"difference\" column in your table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d3a8ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_Acc_AVG</th>\n",
       "      <th>Val_Acc_AVG</th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.530923</td>\n",
       "      <td>0.529236</td>\n",
       "      <td>12.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.535701</td>\n",
       "      <td>0.528748</td>\n",
       "      <td>48.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.530931</td>\n",
       "      <td>0.527760</td>\n",
       "      <td>96.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.530091</td>\n",
       "      <td>0.527545</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.535337</td>\n",
       "      <td>0.527382</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.530328</td>\n",
       "      <td>0.519640</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.530114</td>\n",
       "      <td>0.519611</td>\n",
       "      <td>168.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.534727</td>\n",
       "      <td>0.519477</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.015250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.531014</td>\n",
       "      <td>0.519354</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.531651</td>\n",
       "      <td>0.517572</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LSTM_Acc_AVG  Val_Acc_AVG  Timestep  Neurons  Dropout  Learning  \\\n",
       "105      0.530923     0.529236      12.0    128.0      0.1     0.001   \n",
       "139      0.535701     0.528748      48.0    128.0      0.2     0.001   \n",
       "180      0.530931     0.527760      96.0    128.0      0.2     0.001   \n",
       "33       0.530091     0.527545       2.0    128.0      0.1     0.001   \n",
       "131      0.535337     0.527382      48.0     65.0      0.2     0.001   \n",
       "..            ...          ...       ...      ...      ...       ...   \n",
       "129      0.530328     0.519640      48.0     65.0      0.1     0.010   \n",
       "214      0.530114     0.519611     168.0     65.0      0.2     0.010   \n",
       "60       0.534727     0.519477       6.0     32.0      0.3     0.010   \n",
       "87       0.531014     0.519354      12.0      8.0      0.4     0.001   \n",
       "94       0.531651     0.517572      12.0     32.0      0.4     0.010   \n",
       "\n",
       "     difference  \n",
       "105    0.001687  \n",
       "139    0.006954  \n",
       "180    0.003171  \n",
       "33     0.002545  \n",
       "131    0.007955  \n",
       "..          ...  \n",
       "129    0.010688  \n",
       "214    0.010503  \n",
       "60     0.015250  \n",
       "87     0.011660  \n",
       "94     0.014079  \n",
       "\n",
       "[61 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 = a3.where(a1['LSTM_Acc_AVG']>=0.53)\n",
    "a3 = a3.sort_values(by='Val_Acc_AVG', ascending = False)\n",
    "a3= a3.dropna()\n",
    "a3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ff2b8",
   "metadata": {},
   "source": [
    "# We select this configuration:\n",
    "\n",
    "### Timestep: 12\n",
    "### Neurons: 128\n",
    "### Dropout: 0.1\n",
    "### Learning: 0.001\n",
    "### With a difference of 0.001687132, LSTM Acc. AVG of 0.530923147, and Val Acc.AVG of 0.529236015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf46d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
