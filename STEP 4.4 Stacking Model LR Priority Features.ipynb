{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709bba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from finta import TA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947dd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "# Df_hourly_merge = pd.read_csv('assets/PCHourly2019202_ActualLabel.csv')\n",
    "Df_hourly_merge = pd.read_csv('assets/newfeatures/MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv')\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "Indicatordata = _exponential_smooth(Df_hourly_merge[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "Df_hourly_merge2 = pd.merge(Df_hourly_merge, Indicatordatafinal, left_index=True, right_index=True)\n",
    "\n",
    "Df_hourly_merge2 = Df_hourly_merge2.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binary(value):\n",
    "  if value > 0:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "       'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "       'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "       'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "       '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "for column in columns: \n",
    "    Df_hourly_merge2['Binary{}'.format(column)]  = (Df_hourly_merge2[column] - Df_hourly_merge2[column].shift(1)).apply(binary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca380c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25503"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Df_hourly_merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da43cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>2x_retweets_+_favorites</th>\n",
       "      <th>polarity</th>\n",
       "      <th>W1 Score</th>\n",
       "      <th>Bull_ratio</th>\n",
       "      <th>W Score With Bull Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>BinaryROC</th>\n",
       "      <th>BinaryOBV</th>\n",
       "      <th>Binary20 period CCI</th>\n",
       "      <th>Binary14 period EMV</th>\n",
       "      <th>BinaryVIm</th>\n",
       "      <th>BinaryVIp</th>\n",
       "      <th>Binaryema50</th>\n",
       "      <th>Binaryema21</th>\n",
       "      <th>Binaryema15</th>\n",
       "      <th>Binaryema5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.517857</td>\n",
       "      <td>1.276786</td>\n",
       "      <td>10592.354167</td>\n",
       "      <td>1652.068452</td>\n",
       "      <td>45.605159</td>\n",
       "      <td>9.071429</td>\n",
       "      <td>0.124241</td>\n",
       "      <td>0.264455</td>\n",
       "      <td>3.275000</td>\n",
       "      <td>0.866089</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.685230</td>\n",
       "      <td>0.479419</td>\n",
       "      <td>14341.610169</td>\n",
       "      <td>1852.799031</td>\n",
       "      <td>74.444302</td>\n",
       "      <td>3.644068</td>\n",
       "      <td>0.067950</td>\n",
       "      <td>0.097316</td>\n",
       "      <td>3.342105</td>\n",
       "      <td>0.325240</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.138107</td>\n",
       "      <td>0.670077</td>\n",
       "      <td>21769.074169</td>\n",
       "      <td>2449.731458</td>\n",
       "      <td>68.571009</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>0.120056</td>\n",
       "      <td>0.144203</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>0.882520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.916462</td>\n",
       "      <td>0.670762</td>\n",
       "      <td>36958.090909</td>\n",
       "      <td>2790.968059</td>\n",
       "      <td>100.500076</td>\n",
       "      <td>3.257985</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.110483</td>\n",
       "      <td>5.964286</td>\n",
       "      <td>0.658951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.339394</td>\n",
       "      <td>0.921212</td>\n",
       "      <td>13345.724242</td>\n",
       "      <td>3208.639394</td>\n",
       "      <td>66.105667</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>0.136780</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>4.607143</td>\n",
       "      <td>0.920041</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>5.783333</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>12129.000000</td>\n",
       "      <td>1975.276190</td>\n",
       "      <td>108.150291</td>\n",
       "      <td>7.102381</td>\n",
       "      <td>0.077630</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>3.022222</td>\n",
       "      <td>0.237728</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25499</th>\n",
       "      <td>3.011905</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>14180.595238</td>\n",
       "      <td>1765.121429</td>\n",
       "      <td>31.755382</td>\n",
       "      <td>3.797619</td>\n",
       "      <td>0.095683</td>\n",
       "      <td>0.135134</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>0.578073</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25500</th>\n",
       "      <td>14.400000</td>\n",
       "      <td>2.407143</td>\n",
       "      <td>16161.992857</td>\n",
       "      <td>2084.061905</td>\n",
       "      <td>182.260151</td>\n",
       "      <td>19.214286</td>\n",
       "      <td>0.082271</td>\n",
       "      <td>0.107210</td>\n",
       "      <td>3.648649</td>\n",
       "      <td>0.391172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25501</th>\n",
       "      <td>21.570806</td>\n",
       "      <td>3.270153</td>\n",
       "      <td>11254.296296</td>\n",
       "      <td>1814.954248</td>\n",
       "      <td>428.484448</td>\n",
       "      <td>28.111111</td>\n",
       "      <td>0.070485</td>\n",
       "      <td>0.165014</td>\n",
       "      <td>1.887324</td>\n",
       "      <td>0.311435</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25502</th>\n",
       "      <td>7.505967</td>\n",
       "      <td>0.878282</td>\n",
       "      <td>10556.818616</td>\n",
       "      <td>2143.973747</td>\n",
       "      <td>140.745063</td>\n",
       "      <td>9.262530</td>\n",
       "      <td>0.079407</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>3.945946</td>\n",
       "      <td>0.534052</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25503 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorites  retweets  number_of_followers    following  \\\n",
       "0       6.517857  1.276786         10592.354167  1652.068452   \n",
       "1       2.685230  0.479419         14341.610169  1852.799031   \n",
       "2       2.138107  0.670077         21769.074169  2449.731458   \n",
       "3       1.916462  0.670762         36958.090909  2790.968059   \n",
       "4       4.339394  0.921212         13345.724242  3208.639394   \n",
       "...          ...       ...                  ...          ...   \n",
       "25498   5.783333  0.659524         12129.000000  1975.276190   \n",
       "25499   3.011905  0.392857         14180.595238  1765.121429   \n",
       "25500  14.400000  2.407143         16161.992857  2084.061905   \n",
       "25501  21.570806  3.270153         11254.296296  1814.954248   \n",
       "25502   7.505967  0.878282         10556.818616  2143.973747   \n",
       "\n",
       "       followers_following_ratio  2x_retweets_+_favorites  polarity  W1 Score  \\\n",
       "0                      45.605159                 9.071429  0.124241  0.264455   \n",
       "1                      74.444302                 3.644068  0.067950  0.097316   \n",
       "2                      68.571009                 3.478261  0.120056  0.144203   \n",
       "3                     100.500076                 3.257985  0.143717  0.110483   \n",
       "4                      66.105667                 6.181818  0.136780  0.199699   \n",
       "...                          ...                      ...       ...       ...   \n",
       "25498                 108.150291                 7.102381  0.077630  0.078660   \n",
       "25499                  31.755382                 3.797619  0.095683  0.135134   \n",
       "25500                 182.260151                19.214286  0.082271  0.107210   \n",
       "25501                 428.484448                28.111111  0.070485  0.165014   \n",
       "25502                 140.745063                 9.262530  0.079407  0.135342   \n",
       "\n",
       "       Bull_ratio  W Score With Bull Ratio  ...  BinaryROC  BinaryOBV  \\\n",
       "0        3.275000                 0.866089  ...          0          0   \n",
       "1        3.342105                 0.325240  ...          0          0   \n",
       "2        6.120000                 0.882520  ...          0          0   \n",
       "3        5.964286                 0.658951  ...          0          0   \n",
       "4        4.607143                 0.920041  ...          0          0   \n",
       "...           ...                      ...  ...        ...        ...   \n",
       "25498    3.022222                 0.237728  ...          0          0   \n",
       "25499    4.277778                 0.578073  ...          0          0   \n",
       "25500    3.648649                 0.391172  ...          0          0   \n",
       "25501    1.887324                 0.311435  ...          0          1   \n",
       "25502    3.945946                 0.534052  ...          0          0   \n",
       "\n",
       "       Binary20 period CCI  Binary14 period EMV  BinaryVIm  BinaryVIp  \\\n",
       "0                        0                    0          0          0   \n",
       "1                        0                    0          0          0   \n",
       "2                        0                    0          0          0   \n",
       "3                        0                    0          0          0   \n",
       "4                        1                    0          0          0   \n",
       "...                    ...                  ...        ...        ...   \n",
       "25498                    1                    1          0          1   \n",
       "25499                    0                    1          0          1   \n",
       "25500                    0                    0          1          0   \n",
       "25501                    0                    0          1          0   \n",
       "25502                    0                    0          1          0   \n",
       "\n",
       "       Binaryema50  Binaryema21  Binaryema15  Binaryema5  \n",
       "0                0            0            0           0  \n",
       "1                1            1            1           1  \n",
       "2                0            0            0           0  \n",
       "3                0            0            0           0  \n",
       "4                0            0            0           0  \n",
       "...            ...          ...          ...         ...  \n",
       "25498            0            0            0           0  \n",
       "25499            0            0            0           0  \n",
       "25500            0            0            0           0  \n",
       "25501            1            1            1           1  \n",
       "25502            0            0            0           0  \n",
       "\n",
       "[25503 rows x 178 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_hourly_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8825a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['favorites', 'retweets', 'number_of_followers', 'following',\n",
       "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
       "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
       "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
       "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
       "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
       "       'JMJ_5HMoving_averages', 'Actual_Label',\n",
       "       'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
       "       'Mkt Sentiment', 'Crypto Sentiment',\n",
       "       'Historically Optimal SMA(s-t)', 'Historically Optimal SMA(l-t)',\n",
       "       'Historically Optimal WMA(s-t)', 'Historically Optimal WMA(l-t)',\n",
       "       'Historically Optimal EMA(s-t)', 'Historically Optimal EMA(l-t)',\n",
       "       'Twitter Hourly Favorites SMA(s-t)',\n",
       "       'Twitter Hourly Favorites SMA(l-t)',\n",
       "       'Twitter Hourly Favorites WMA(s-t)',\n",
       "       'Twitter Hourly Favorites WMA(l-t)',\n",
       "       'Twitter Hourly Favorites EMA(s-t)',\n",
       "       'Twitter Hourly Favorites EMA(l-t)',\n",
       "       'Twitter Hourly Retweets SMA(s-t)',\n",
       "       'Twitter Hourly Retweets SMA(l-t)',\n",
       "       'Twitter Hourly Retweets WMA(s-t)',\n",
       "       'Twitter Hourly Retweets WMA(l-t)',\n",
       "       'Twitter Hourly Retweets EMA(s-t)',\n",
       "       'Twitter Hourly Retweets EMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
       "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
       "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
       "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
       "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
       "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
       "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
       "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
       "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
       "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
       "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
       "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
       "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
       "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
       "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
       "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
       "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
       "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
       "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
       "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
       "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
       "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
       "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
       "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
       "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
       "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
       "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
       "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
       "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
       "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
       "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
       "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
       "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
       "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
       "       'Binaryema5'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_hourly_merge2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3882cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b89263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = Df_hourly_merge2\n",
    "data = data.dropna()\n",
    "\n",
    "feature_names_JMJ = [\n",
    "'# of Hourly Trades SMA(l-t)',\n",
    "'# of Hourly Trades SMA(s-t)',\n",
    "'# of Hourly Trades WMA(l-t)',\n",
    "'14 period MFI',\n",
    "'14 period STOCH %K',\n",
    "'20 period CCI',\n",
    "'2x_retweets_+_favorites',\n",
    "'3MovingAverage',\n",
    "'BinaryJMJ_3HMoving_averages',\n",
    "'BinaryJMJ_5HMoving_averages',\n",
    "'BinaryMFV',\n",
    "'BinaryOpen',\n",
    "'BinaryQuote Asset Volume',\n",
    "'BinaryVolume',\n",
    "'Bitcoin_Google_Trend_Score',\n",
    "'BTC_Google_Trend_Score',\n",
    "'Bull_ratio',\n",
    "'ema5',\n",
    "'ema50',\n",
    "'favorites',\n",
    "'followers_following_ratio',\n",
    "'following',\n",
    "'Historically Optimal EMA(l-t)',\n",
    "'Historically Optimal SMA(s-t)',\n",
    "'Historically Optimal WMA(s-t)',\n",
    "'MFV',\n",
    "'Mkt Sentiment',\n",
    "'normVol',\n",
    "'Number of Trades',\n",
    "'OBV',\n",
    "'polarity',\n",
    "'Quote Asset Volume',\n",
    "'Quote Asset Volume SMA(l-t)',\n",
    "'Quote Asset Volume SMA(s-t)',\n",
    "'retweets',\n",
    "'ROC',\n",
    "'TB Base Volume',\n",
    "'TB Base Volume EMA(l-t)',\n",
    "'TB Base Volume EMA(s-t)',\n",
    "'TB Base Volume SMA(l-t)',\n",
    "'TB Base Volume WMA(l-t)',\n",
    "'TB Base Volume WMA(s-t)',\n",
    "'TB Quote Volume',\n",
    "'TB Quote Volume WMA(s-t)',\n",
    "'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "'Twitter Hourly Favorites EMA(s-t)',\n",
    "'Twitter Hourly Favorites WMA(l-t)',\n",
    "'Twitter Hourly Favorites WMA(s-t)',\n",
    "'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "'Twitter Hourly Follower Exposure WMA(l-t)' ,\n",
    "'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "'Twitter Hourly Retweets EMA(l-t)',\n",
    "'Twitter Hourly Retweets SMA(l-t)',\n",
    "'Twitter Hourly Retweets SMA(s-t)',\n",
    "'Twitter Hourly Retweets WMA(s-t)',\n",
    "'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "'Twitter W1 Score EMA(l-t)',\n",
    "'Twitter W1 Score EMA(s-t)',\n",
    "'Twitter W1 Score SMA(l-t)',\n",
    "'Twitter W1 Score SMA(s-t)',\n",
    "'Twitter W1 Score WMA(l-t)',\n",
    "'Twitter W1 Score WMA(s-t)',\n",
    "'VIm',\n",
    "'Volume',\n",
    "'W1 Score']\n",
    "\n",
    "X_JMJ = data[feature_names_JMJ]\n",
    "y_JMJ = data['Actual_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71371fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names_JMJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b15bc",
   "metadata": {},
   "source": [
    "## BASE ESTIMATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce48f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _LogisticRegression(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new random forest classifier\n",
    "    #et = ExtraTreesClassifier()\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_lr = {\n",
    "                    'C': [0.01, 0.1, 1, 10, 100], \n",
    "                    \"penalty\":['l2'],\n",
    "                    'solver': ['lbfgs'],\n",
    "                    'max_iter':[1000]\n",
    "        \n",
    "        \n",
    "        \n",
    "                    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    lr_gs = GridSearchCV(lr, params_lr, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    lr_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    lr_best = lr_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(lr_gs.best_params_)\n",
    "    \n",
    "    prediction = lr_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return lr_best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aaaebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_AdaBoostClassifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new random forest classifier\n",
    "    abc = AdaBoostClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_abc =  {\n",
    "                'n_estimators': [20, 50, 70, 100],\n",
    "                'learning_rate' : [0.001, 0.01, 0.1, 0.2]\n",
    "                }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    abc_gs = GridSearchCV(abc, params_abc, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    abc_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    abc_best = abc_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(abc_gs.best_params_)\n",
    "    \n",
    "    prediction = abc_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return abc_best\n",
    "    \n",
    "# abc_model = _train_AdaBoostClassifier(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d99641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _train_LDA(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    \n",
    "    param_lda = {\n",
    "                'solver': ['svd', 'lsqr', 'eigen']\n",
    "                                  \n",
    "                 }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    lda_gs = GridSearchCV(lda, param_lda, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    lda_gs.fit(X_train, y_train)\n",
    "              \n",
    "    # Save best model\n",
    "    lda_best = lda_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(lda_gs.best_params_)\n",
    "    \n",
    "    prediction = lda_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return lda_best\n",
    "    \n",
    "    \n",
    "# lda_model = _train_LDA(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4fe796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _GradientBoosingClassifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a ne\n",
    "    GBC = GradientBoostingClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_nnclf = {\n",
    "    \"loss\":[\"log_loss\"],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "#     \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[0.5, 1.0],\n",
    "    \"n_estimators\":[100]\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    GBC_gs = GridSearchCV(GBC, params_nnclf, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    GBC_gs.fit(X_train, y_train)\n",
    "#     GBC.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Save best model\n",
    "    GBC_best = GBC_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(GBC_gs.best_params_)\n",
    "    \n",
    "    prediction = GBC_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return GBC_best\n",
    "    \n",
    "# GBC_model = _GradientBoosingClassifier(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75264452",
   "metadata": {},
   "source": [
    "## FINAL MODEL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11fdf156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2316 2317 2318] [2319 2320 2321 ... 4633 4634 4635]\n",
      "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.40      0.46      1084\n",
      "         1.0       0.57      0.69      0.63      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.56      0.55      2317\n",
      "\n",
      "[[436 648]\n",
      " [377 856]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.67      0.58      1084\n",
      "         1.0       0.60      0.43      0.50      1233\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.56      0.54      0.54      2317\n",
      "\n",
      "[[724 360]\n",
      " [697 536]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 14 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54418522 0.54418522        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.05      0.09      1084\n",
      "         1.0       0.54      0.97      0.69      1233\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.56      0.51      0.39      2317\n",
      "weighted avg       0.56      0.54      0.41      2317\n",
      "\n",
      "[[  52 1032]\n",
      " [  37 1196]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49      1084\n",
      "         1.0       0.57      0.65      0.61      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.56      0.55      2317\n",
      "\n",
      "[[492 592]\n",
      " [433 800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.20      0.29      1084\n",
      "         1.0       0.54      0.84      0.66      1233\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.52      0.48      2317\n",
      "weighted avg       0.54      0.54      0.49      2317\n",
      "\n",
      "[[ 219  865]\n",
      " [ 197 1036]]\n",
      "ABC Accuracy = 0.5438066465256798 , LDA Accuracy = 0.5386275356063875 , LR Accuracy = 0.5576176089771256 , GBC Accuracy = 0.5576176089771256 , LTSM Accuracy = 0.5416486836426413\n",
      " \n",
      "[   0    1    2 ... 4633 4634 4635] [4636 4637 4638 ... 6950 6951 6952]\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.33      0.43      1178\n",
      "         1.0       0.53      0.78      0.63      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.57      0.55      0.53      2317\n",
      "weighted avg       0.57      0.55      0.53      2317\n",
      "\n",
      "[[392 786]\n",
      " [255 884]]\n",
      "{'learning_rate': 0.1, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.37      0.46      1178\n",
      "         1.0       0.53      0.74      0.62      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.56      0.56      0.54      2317\n",
      "weighted avg       0.57      0.55      0.54      2317\n",
      "\n",
      "[[436 742]\n",
      " [294 845]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.55392325 0.554139          nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.04      0.08      1178\n",
      "         1.0       0.50      0.97      0.66      1139\n",
      "\n",
      "    accuracy                           0.50      2317\n",
      "   macro avg       0.56      0.51      0.37      2317\n",
      "weighted avg       0.56      0.50      0.36      2317\n",
      "\n",
      "[[  50 1128]\n",
      " [  30 1109]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.30      0.40      1178\n",
      "         1.0       0.53      0.80      0.64      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.57      0.55      0.52      2317\n",
      "weighted avg       0.57      0.55      0.52      2317\n",
      "\n",
      "[[350 828]\n",
      " [223 916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.32      0.42      1178\n",
      "         1.0       0.53      0.79      0.63      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.57      0.55      0.52      2317\n",
      "weighted avg       0.57      0.55      0.52      2317\n",
      "\n",
      "[[373 805]\n",
      " [243 896]]\n",
      "ABC Accuracy = 0.552870090634441 , LDA Accuracy = 0.5002157962883038 , LR Accuracy = 0.5507121277514027 , GBC Accuracy = 0.5463962019853259 , LTSM Accuracy = 0.5476909797151489\n",
      " \n",
      "[   0    1    2 ... 6950 6951 6952] [6953 6954 6955 ... 9267 9268 9269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.48      0.52      1144\n",
      "         1.0       0.55      0.63      0.59      1173\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.55      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[548 596]\n",
      " [434 739]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.59      0.58      1144\n",
      "         1.0       0.58      0.55      0.57      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[675 469]\n",
      " [522 651]]\n",
      "{'solver': 'eigen'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.63      0.58      1144\n",
      "         1.0       0.57      0.48      0.52      1173\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[719 425]\n",
      " [605 568]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.61      0.58      1144\n",
      "         1.0       0.57      0.51      0.54      1173\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[699 445]\n",
      " [574 599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.47      0.51      1144\n",
      "         1.0       0.55      0.63      0.59      1173\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[540 604]\n",
      " [433 740]]\n",
      "ABC Accuracy = 0.5722917565817868 , LDA Accuracy = 0.5554596460940872 , LR Accuracy = 0.5554596460940872 , GBC Accuracy = 0.5602071644367717 , LTSM Accuracy = 0.5524384980578334\n",
      " \n",
      "[   0    1    2 ... 9267 9268 9269] [ 9270  9271  9272 ... 11584 11585 11586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.55      0.54      1127\n",
      "         1.0       0.56      0.55      0.55      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[618 509]\n",
      " [538 652]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.61      0.56      1127\n",
      "         1.0       0.57      0.48      0.52      1190\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[685 442]\n",
      " [613 577]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53743258 0.53743258        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.63      0.57      1127\n",
      "         1.0       0.55      0.44      0.49      1190\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.54      0.53      0.53      2317\n",
      "\n",
      "[[707 420]\n",
      " [667 523]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.58      0.56      1127\n",
      "         1.0       0.57      0.52      0.54      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[653 474]\n",
      " [572 618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.55      0.54      1127\n",
      "         1.0       0.56      0.54      0.55      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[619 508]\n",
      " [543 647]]\n",
      "ABC Accuracy = 0.5446698316788952 , LDA Accuracy = 0.5308588692274493 , LR Accuracy = 0.5481225722917565 , GBC Accuracy = 0.5485541648683643 , LTSM Accuracy = 0.5463962019853259\n",
      " \n",
      "[    0     1     2 ... 11584 11585 11586] [11587 11588 11589 ... 13901 13902 13903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.60      0.57      1125\n",
      "         1.0       0.59      0.53      0.56      1192\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[678 447]\n",
      " [558 634]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.65      0.59      1125\n",
      "         1.0       0.59      0.47      0.52      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[736 389]\n",
      " [637 555]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53404748 0.53404748        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.43      0.49      1125\n",
      "         1.0       0.56      0.68      0.61      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.55      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[483 642]\n",
      " [381 811]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.63      0.58      1125\n",
      "         1.0       0.58      0.48      0.53      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[714 411]\n",
      " [616 576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.67      0.59      1125\n",
      "         1.0       0.59      0.44      0.51      1192\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.55      0.55      2317\n",
      "\n",
      "[[754 371]\n",
      " [662 530]]\n",
      "ABC Accuracy = 0.5571860164005179 , LDA Accuracy = 0.5584807941303409 , LR Accuracy = 0.5662494605092793 , GBC Accuracy = 0.5567544238239103 , LTSM Accuracy = 0.5541648683642642\n",
      " \n",
      "[    0     1     2 ... 13901 13902 13903] [13904 13905 13906 ... 16218 16219 16220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.47      0.51      1120\n",
      "         1.0       0.56      0.63      0.59      1197\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[530 590]\n",
      " [448 749]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.62      0.57      1120\n",
      "         1.0       0.57      0.46      0.51      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[699 421]\n",
      " [647 550]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53783223 0.53783223        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.43      0.48      1120\n",
      "         1.0       0.55      0.64      0.59      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[486 634]\n",
      " [430 767]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49      1120\n",
      "         1.0       0.55      0.62      0.58      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[509 611]\n",
      " [455 742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.48      0.51      1120\n",
      "         1.0       0.56      0.61      0.58      1197\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[537 583]\n",
      " [465 732]]\n",
      "ABC Accuracy = 0.5390591281829953 , LDA Accuracy = 0.540785498489426 , LR Accuracy = 0.5520069054812258 , GBC Accuracy = 0.5399223133362107 , LTSM Accuracy = 0.5476909797151489\n",
      " \n",
      "[    0     1     2 ... 16218 16219 16220] [16221 16222 16223 ... 18535 18536 18537]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.84      0.62      1100\n",
      "         1.0       0.59      0.21      0.31      1217\n",
      "\n",
      "    accuracy                           0.51      2317\n",
      "   macro avg       0.54      0.52      0.46      2317\n",
      "weighted avg       0.54      0.51      0.46      2317\n",
      "\n",
      "[[922 178]\n",
      " [960 257]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.65      0.57      1100\n",
      "         1.0       0.57      0.43      0.49      1217\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.53      0.53      2317\n",
      "\n",
      "[[714 386]\n",
      " [698 519]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53628107 0.53628107        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.78      0.60      1100\n",
      "         1.0       0.58      0.27      0.37      1217\n",
      "\n",
      "    accuracy                           0.51      2317\n",
      "   macro avg       0.54      0.53      0.49      2317\n",
      "weighted avg       0.54      0.51      0.48      2317\n",
      "\n",
      "[[857 243]\n",
      " [883 334]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.46      0.49      1100\n",
      "         1.0       0.55      0.60      0.58      1217\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[509 591]\n",
      " [481 736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.87      0.62      1100\n",
      "         1.0       0.59      0.18      0.27      1217\n",
      "\n",
      "    accuracy                           0.50      2317\n",
      "   macro avg       0.54      0.52      0.45      2317\n",
      "weighted avg       0.54      0.50      0.44      2317\n",
      "\n",
      "[[ 952  148]\n",
      " [1000  217]]\n",
      "ABC Accuracy = 0.5321536469572723 , LDA Accuracy = 0.5140267587397497 , LR Accuracy = 0.5088476478204574 , GBC Accuracy = 0.5373327578765645 , LTSM Accuracy = 0.5045317220543807\n",
      " \n",
      "[    0     1     2 ... 18535 18536 18537] [18538 18539 18540 ... 20852 20853 20854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.47      0.50      1139\n",
      "         1.0       0.54      0.60      0.57      1178\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[541 598]\n",
      " [470 708]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.58      0.55      1139\n",
      "         1.0       0.54      0.48      0.51      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[661 478]\n",
      " [608 570]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54865581 0.54865581        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.75      0.61      1139\n",
      "         1.0       0.56      0.31      0.40      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.54      0.53      0.50      2317\n",
      "weighted avg       0.54      0.53      0.50      2317\n",
      "\n",
      "[[856 283]\n",
      " [815 363]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.35      0.43      1139\n",
      "         1.0       0.53      0.71      0.61      1178\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.53      0.52      2317\n",
      "weighted avg       0.54      0.54      0.52      2317\n",
      "\n",
      "[[401 738]\n",
      " [339 839]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.47      0.50      1139\n",
      "         1.0       0.54      0.61      0.58      1178\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[538 601]\n",
      " [459 719]]\n",
      "ABC Accuracy = 0.5312904618040569 , LDA Accuracy = 0.5261113508847648 , LR Accuracy = 0.5390591281829953 , GBC Accuracy = 0.5351747949935262 , LTSM Accuracy = 0.5425118687958567\n",
      " \n",
      "[    0     1     2 ... 20852 20853 20854] [20855 20856 20857 ... 23169 23170 23171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.46      0.49      1151\n",
      "         1.0       0.53      0.61      0.57      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[526 625]\n",
      " [457 709]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.54      1151\n",
      "         1.0       0.53      0.50      0.51      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[637 514]\n",
      " [584 582]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54269959 0.54269959        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.54      0.54      1151\n",
      "         1.0       0.55      0.54      0.54      1166\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[625 526]\n",
      " [534 632]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.38      0.45      1151\n",
      "         1.0       0.53      0.69      0.60      1166\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.54      0.53      2317\n",
      "\n",
      "[[442 709]\n",
      " [359 807]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49      1151\n",
      "         1.0       0.53      0.62      0.57      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[513 638]\n",
      " [447 719]]\n",
      "ABC Accuracy = 0.5261113508847648 , LDA Accuracy = 0.5425118687958567 , LR Accuracy = 0.5330168321104877 , GBC Accuracy = 0.5390591281829953 , LTSM Accuracy = 0.5317220543806647\n",
      " \n",
      "[    0     1     2 ... 23169 23170 23171] [23172 23173 23174 ... 25486 25487 25488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.55      0.55      1166\n",
      "         1.0       0.55      0.55      0.55      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[646 520]\n",
      " [517 634]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.57      0.56      1166\n",
      "         1.0       0.55      0.53      0.54      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[662 504]\n",
      " [542 609]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 35 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53952862 0.53952862        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.49      0.52      1166\n",
      "         1.0       0.54      0.60      0.57      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[573 593]\n",
      " [461 690]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.46      0.51      1166\n",
      "         1.0       0.54      0.64      0.58      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[539 627]\n",
      " [419 732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.55      0.55      1166\n",
      "         1.0       0.55      0.55      0.55      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[645 521]\n",
      " [516 635]]\n",
      "ABC Accuracy = 0.5485541648683643 , LDA Accuracy = 0.5451014242555028 , LR Accuracy = 0.5524384980578334 , GBC Accuracy = 0.5485541648683643 , LTSM Accuracy = 0.5524384980578334\n",
      " \n",
      " \n",
      "ABC Accuracy = 0.5447993094518775\n",
      "LDA Accuracy = 0.5352179542511869\n",
      "LR Accuracy = 0.546353042727665\n",
      "GBC Accuracy = 0.5469572723349159\n",
      "LTSM Accuracy = 0.5421234354769098\n",
      " \n",
      "Wall time: 6h 54min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "LTSM_RESULTS = []\n",
    "abc_RESULTS = []\n",
    "lda_RESULTS = []\n",
    "lr_RESULTS =[]\n",
    "GBC_RESULTS = []\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_JMJ):\n",
    "    print(train_index, test_index)\n",
    "    \n",
    "    X_train, X_test = X_JMJ.iloc[train_index], X_JMJ.iloc[test_index]\n",
    "    y_train, y_test = y_JMJ.iloc[train_index], y_JMJ.iloc[test_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #Setting up the Base Estimators\n",
    "    lr_model = _LogisticRegression(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    abc_model = _train_AdaBoostClassifier(X_train_scaled, y_train,  X_test_scaled, y_test)\n",
    "    lda_model = _train_LDA(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    GBC_model = _GradientBoosingClassifier(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "    # Define the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('lr', lr_model),('abc', abc_model),('lda', lda_model), ('GBC',GBC_model)], \n",
    "        final_estimator=lr_model,\n",
    "        cv=5,\n",
    "        passthrough=True,\n",
    "        stack_method='predict_proba'\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier on the training data\n",
    "    stacking_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = stacking_classifier.predict(X_test_scaled)\n",
    "    testy_pred = (y_pred >= 0.5).astype(int)\n",
    "    \n",
    "    abc_prediction = abc_model.predict(X_test_scaled)\n",
    "    lda_prediction = lda_model.predict(X_test_scaled)\n",
    "    lr_prediction = lr_model.predict(X_test_scaled)\n",
    "    GBC_prediction = GBC_model.predict(X_test_scaled)\n",
    "\n",
    "    \n",
    "    abc_accuracy = accuracy_score(y_test.values, abc_prediction)\n",
    "    lda_accuracy = accuracy_score(y_test.values, lda_prediction)\n",
    "    lr_accuracy = accuracy_score(y_test.values, lr_prediction)\n",
    "    GBC_accuracy = accuracy_score(y_test.values, GBC_prediction)\n",
    "    LTSMaccurary = accuracy_score (y_test, testy_pred)   \n",
    "   \n",
    "\n",
    "\n",
    "    abc_RESULTS.append(abc_accuracy)\n",
    "    lda_RESULTS.append(lda_accuracy)\n",
    "    lr_RESULTS.append(lr_accuracy)\n",
    "    GBC_RESULTS.append(GBC_accuracy)\n",
    "    LTSM_RESULTS.append(LTSMaccurary)\n",
    "        \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, testy_pred))\n",
    "    print(confusion_matrix(y_test, testy_pred))\n",
    "    \n",
    "    print('ABC Accuracy = ' + str(abc_accuracy),', LDA Accuracy = ' + str(lda_accuracy),', LR Accuracy = ' + str(lr_accuracy),', GBC Accuracy = ' + str(GBC_accuracy),', LTSM Accuracy = ' + str(LTSMaccurary))#,GBC_accuracy, ensemble_accuracy)    \n",
    "    print(' ')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "print(' ')\n",
    "print('ABC Accuracy = ' + str( sum(abc_RESULTS) / len(abc_RESULTS)))\n",
    "print('LDA Accuracy = ' + str( sum(lda_RESULTS) / len(lda_RESULTS)))\n",
    "print('LR Accuracy = ' + str( sum(lr_RESULTS) / len(lr_RESULTS)))\n",
    "print('GBC Accuracy = ' + str( sum(GBC_RESULTS) / len(GBC_RESULTS)))\n",
    "print('LTSM Accuracy = ' + str( sum(LTSM_RESULTS) / len(LTSM_RESULTS)))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65e739e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.001, n_estimators=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lda</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lr',\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               ('abc',\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               ('lda', LinearDiscriminantAnalysis()),\n",
       "                               ('GBC',\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
       "                   passthrough=True, stack_method='predict_proba')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "585825d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(cv=5,\n",
      "                   estimators=[('lr',\n",
      "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
      "                               ('abc',\n",
      "                                AdaBoostClassifier(learning_rate=0.001,\n",
      "                                                   n_estimators=20)),\n",
      "                               ('lda', LinearDiscriminantAnalysis()),\n",
      "                               ('GBC',\n",
      "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
      "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
      "                   passthrough=True, stack_method='predict_proba')\n"
     ]
    }
   ],
   "source": [
    "print(stacking_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0731af",
   "metadata": {},
   "source": [
    "#### SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150d57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#saving model\n",
    "pkl_filename = 'model/Priority_Feature_Stacking_LR_model_JT2019to2022TEST_news_google.pkl'\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(stacking_classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948bd3d",
   "metadata": {},
   "source": [
    "#### LOADING MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfb86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pkl_filename = 'model/Priority_Feature_Stacking_LR_model_JT2019to2022TEST_news_google.pkl'\n",
    "with open(pkl_filename, 'rb') as file: \n",
    "    Model2 = pickle.load(file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be14ad0",
   "metadata": {},
   "source": [
    "# TESTING RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4a398",
   "metadata": {},
   "source": [
    "### Testing with Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdcebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models = [Model1,abc_model, rc_model, lda_model,lr_model,GBC_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7d9b5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.47      0.51      3625\n",
      "         1.0       0.54      0.63      0.58      3629\n",
      "\n",
      "    accuracy                           0.55      7254\n",
      "   macro avg       0.55      0.55      0.54      7254\n",
      "weighted avg       0.55      0.55      0.54      7254\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "January = 'Test data/PCHourly202201.csv'\n",
    "February= 'Test data/PCHourly202202.csv'\n",
    "March = 'Test data/PCHourly202203.csv'\n",
    "April = 'Test data/PCHourly202204.csv'\n",
    "May= 'Test data/PCHourly202205.csv'\n",
    "June = 'Test data/PCHourly202206.csv'\n",
    "July = 'Test data/PCHourly202207.csv'\n",
    "August= 'Test data/PCHourly202208.csv'\n",
    "September = 'Test data/PCHourly202209.csv'\n",
    "October = 'Test data/PCHourly202210.csv'\n",
    "\n",
    "testdata2022 ='assets/newfeatures/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "\n",
    "    \n",
    "    feature_names_JMJ = [\n",
    "    '# of Hourly Trades SMA(l-t)',\n",
    "    '# of Hourly Trades SMA(s-t)',\n",
    "    '# of Hourly Trades WMA(l-t)',\n",
    "    '14 period MFI',\n",
    "    '14 period STOCH %K',\n",
    "    '20 period CCI',\n",
    "    '2x_retweets_+_favorites',\n",
    "    '3MovingAverage',\n",
    "    'BinaryJMJ_3HMoving_averages',\n",
    "    'BinaryJMJ_5HMoving_averages',\n",
    "    'BinaryMFV',\n",
    "    'BinaryOpen',\n",
    "    'BinaryQuote Asset Volume',\n",
    "    'BinaryVolume',\n",
    "    'Bitcoin_Google_Trend_Score',\n",
    "    'BTC_Google_Trend_Score',\n",
    "    'Bull_ratio',\n",
    "    'ema5',\n",
    "    'ema50',\n",
    "    'favorites',\n",
    "    'followers_following_ratio',\n",
    "    'following',\n",
    "    'Historically Optimal EMA(l-t)',\n",
    "    'Historically Optimal SMA(s-t)',\n",
    "    'Historically Optimal WMA(s-t)',\n",
    "    'MFV',\n",
    "    'Mkt Sentiment',\n",
    "    'normVol',\n",
    "    'Number of Trades',\n",
    "    'OBV',\n",
    "    'polarity',\n",
    "    'Quote Asset Volume',\n",
    "    'Quote Asset Volume SMA(l-t)',\n",
    "    'Quote Asset Volume SMA(s-t)',\n",
    "    'retweets',\n",
    "    'ROC',\n",
    "    'TB Base Volume',\n",
    "    'TB Base Volume EMA(l-t)',\n",
    "    'TB Base Volume EMA(s-t)',\n",
    "    'TB Base Volume SMA(l-t)',\n",
    "    'TB Base Volume WMA(l-t)',\n",
    "    'TB Base Volume WMA(s-t)',\n",
    "    'TB Quote Volume',\n",
    "    'TB Quote Volume WMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "    'Twitter Hourly Favorites EMA(s-t)',\n",
    "    'Twitter Hourly Favorites WMA(l-t)',\n",
    "    'Twitter Hourly Favorites WMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure WMA(l-t)' ,\n",
    "    'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "    'Twitter Hourly Retweets EMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(s-t)',\n",
    "    'Twitter Hourly Retweets WMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "    'Twitter W1 Score EMA(l-t)',\n",
    "    'Twitter W1 Score EMA(s-t)',\n",
    "    'Twitter W1 Score SMA(l-t)',\n",
    "    'Twitter W1 Score SMA(s-t)',\n",
    "    'Twitter W1 Score WMA(l-t)',\n",
    "    'Twitter W1 Score WMA(s-t)',\n",
    "    'VIm',\n",
    "    'Volume',\n",
    "    'W1 Score']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    predict_y=  stacking_classifier.predict(X_test_scaled)\n",
    "    PredictDF['Predicted_Label']= predict_y\n",
    "\n",
    "    print(classification_report(y_test, predict_y))   \n",
    "    \n",
    "    # confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "    confusion_mc = confusion_matrix(PredictDF['Actual_Label'], PredictDF['Predicted_Label'])\n",
    "    df_cm = pd.DataFrame(confusion_mc, \n",
    "                         index = [i for i in range(0,2)], columns = [i for i in range(0,2)])\n",
    "\n",
    "\n",
    "    PredictDF['ValueActual'] =0\n",
    "    PredictDF['BTCValueActual'] =0\n",
    "    if PredictDF.loc[PredictDF.index[0],'Actual_Label']==0.0:\n",
    "        PredictDF.loc[PredictDF.index[0],'ValueActual']=1000\n",
    "    else:\n",
    "        PredictDF.loc[PredictDF.index[0],'BTCValueActual']=round((1000/PredictDF.loc[PredictDF.index[0],'Close']),5)\n",
    "\n",
    "\n",
    "    for current in range(1, len(PredictDF.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if PredictDF.loc[PredictDF.index[current],'Actual_Label']==0 and PredictDF.loc[PredictDF.index[previous],'BTCValueActual']==0:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual']=PredictDF.loc[PredictDF.index[previous],'ValueActual']\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Actual_Label']==1 and PredictDF.loc[PredictDF.index[previous],'ValueActual'] ==0 :\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual']= 0\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValueActual']=round(PredictDF.loc[PredictDF.index[previous],'BTCValueActual'],3)\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Actual_Label']==1:\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValueActual'] = round((PredictDF.loc[PredictDF.index[previous],'ValueActual']/PredictDF.loc[PredictDF.index[current],'Close']),5)\n",
    "        else:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual'] = round((PredictDF.loc[PredictDF.index[previous],'BTCValueActual'] *PredictDF.loc[PredictDF.index[current],'Close']),3)\n",
    "\n",
    "\n",
    "    PredictDF['ValuePredicted'] =0\n",
    "    PredictDF['BTCValuePredicted'] =0\n",
    "    if PredictDF.loc[PredictDF.index[0],'Predicted_Label']==0.0:\n",
    "        PredictDF.loc[PredictDF.index[0],'ValuePredicted']=1000\n",
    "    else:\n",
    "        PredictDF.loc[PredictDF.index[0],'BTCValuePredicted']=round((1000/PredictDF.loc[PredictDF.index[0],'Close']),5)\n",
    "\n",
    "\n",
    "    for current in range(1, len(PredictDF.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if PredictDF.loc[PredictDF.index[current],'Predicted_Label']==0 and PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted']==0:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted']=PredictDF.loc[PredictDF.index[previous],'ValuePredicted']\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Predicted_Label']==1 and PredictDF.loc[PredictDF.index[previous],'ValuePredicted'] ==0 :\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted']= 0\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValuePredicted']=round(PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted'],3)\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Predicted_Label']==1:\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValuePredicted'] = round((PredictDF.loc[PredictDF.index[previous],'ValuePredicted']/PredictDF.loc[PredictDF.index[current],'Close']),5)\n",
    "        else:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted'] = round((PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted'] *PredictDF.loc[PredictDF.index[current],'Close']),3)\n",
    "    df = PredictDF.mask(PredictDF==0).ffill().iloc[[-1]]\n",
    "    LastPredictvalue = df['ValuePredicted'].values[0]\n",
    "    LastPredictBTC = df['BTCValuePredicted'].values[0]\n",
    "    # LastPredictvalue= PredictDF['ValuePredicted'][PredictDF['ValuePredicted'].to_numpy().nonzero()[0][-1]+1]\n",
    "    # LastPredictBTC= PredictDF['BTCValuePredicted'][PredictDF['BTCValuePredicted'].to_numpy().nonzero()[0][-1]+1]\n",
    "\n",
    "    #     print('Total USD Value and BTC Benchmark Actual Label: ${:,.2f} and {:,.2f} BTC'.format (max(PredictDF['ValueActual']),max(PredictDF['BTCValueActual'])))#, )       \n",
    "    #     print('Total USD Value and BTC Benchmark Actual Label: ${:,.2f} and {:,.2f} BTC'.format (LastPredictvalue,LastPredictBTC))#, )       \n",
    "    #     print (' ')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "    plt.title('Assessment for: {}\\nAccuracy:{:.3f}\\nPrecision:{:.3f}\\nRecall:{:.3f}\\nF1:{:.3f}\\nBenchmark USD Value and BTC  ${:,.2f} and {:,.2f}\\nPredicted USD Value and BTC ${:,.2f} and {:,.2f}'.format(x, accuracy_score(PredictDF['Actual_Label'],PredictDF['Predicted_Label']),\n",
    "                                                                        precision_score(PredictDF['Actual_Label'],PredictDF['Predicted_Label']),\n",
    "                                                                                    recall_score(PredictDF['Actual_Label'], PredictDF['Predicted_Label']),\n",
    "                                                                                    f1_score(PredictDF['Actual_Label'], PredictDF['Predicted_Label']),\n",
    "                                                                                     max(PredictDF['ValueActual']),max(PredictDF['BTCValueActual']),\n",
    "                                                                                     LastPredictvalue,LastPredictBTC\n",
    "                                                                                    ))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffcbfac",
   "metadata": {},
   "source": [
    "## Trying with Thesholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9941c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.10      0.17       434\n",
      "         1.0       0.57      0.93      0.71       562\n",
      "\n",
      "    accuracy                           0.57       996\n",
      "   macro avg       0.55      0.52      0.44       996\n",
      "weighted avg       0.55      0.57      0.47       996\n",
      "\n",
      "[[ 43 391]\n",
      " [ 38 524]]\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "testdata2022 ='assets/newfeatures/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.6\n",
    "LowerThresshold = 0.4\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "#     feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "#            'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "#            'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "#            'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "#            'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "#            'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages',\n",
    "#            '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "#            '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "#            '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5',\n",
    "#            'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "#            'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "#            'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "#            'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "#            'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "#            'BinaryLow', 'BinaryClose', 'BinaryVolume', 'BinaryQuote Asset Volume',\n",
    "#            'BinaryNumber of Trades', 'BinaryTB Base Volume',\n",
    "#            'BinaryTB Quote Volume', 'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "#            'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages']\n",
    "    \n",
    "    \n",
    "    feature_names_JMJ = [\n",
    "    '# of Hourly Trades SMA(l-t)',\n",
    "    '# of Hourly Trades SMA(s-t)',\n",
    "    '# of Hourly Trades WMA(l-t)',\n",
    "    '14 period MFI',\n",
    "    '14 period STOCH %K',\n",
    "    '20 period CCI',\n",
    "    '2x_retweets_+_favorites',\n",
    "    '3MovingAverage',\n",
    "    'BinaryJMJ_3HMoving_averages',\n",
    "    'BinaryJMJ_5HMoving_averages',\n",
    "    'BinaryMFV',\n",
    "    'BinaryOpen',\n",
    "    'BinaryQuote Asset Volume',\n",
    "    'BinaryVolume',\n",
    "    'Bitcoin_Google_Trend_Score',\n",
    "    'BTC_Google_Trend_Score',\n",
    "    'Bull_ratio',\n",
    "    'ema5',\n",
    "    'ema50',\n",
    "    'favorites',\n",
    "    'followers_following_ratio',\n",
    "    'following',\n",
    "    'Historically Optimal EMA(l-t)',\n",
    "    'Historically Optimal SMA(s-t)',\n",
    "    'Historically Optimal WMA(s-t)',\n",
    "    'MFV',\n",
    "    'Mkt Sentiment',\n",
    "    'normVol',\n",
    "    'Number of Trades',\n",
    "    'OBV',\n",
    "    'polarity',\n",
    "    'Quote Asset Volume',\n",
    "    'Quote Asset Volume SMA(l-t)',\n",
    "    'Quote Asset Volume SMA(s-t)',\n",
    "    'retweets',\n",
    "    'ROC',\n",
    "    'TB Base Volume',\n",
    "    'TB Base Volume EMA(l-t)',\n",
    "    'TB Base Volume EMA(s-t)',\n",
    "    'TB Base Volume SMA(l-t)',\n",
    "    'TB Base Volume WMA(l-t)',\n",
    "    'TB Base Volume WMA(s-t)',\n",
    "    'TB Quote Volume',\n",
    "    'TB Quote Volume WMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "    'Twitter Hourly Favorites EMA(s-t)',\n",
    "    'Twitter Hourly Favorites WMA(l-t)',\n",
    "    'Twitter Hourly Favorites WMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure WMA(l-t)' ,\n",
    "    'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "    'Twitter Hourly Retweets EMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(s-t)',\n",
    "    'Twitter Hourly Retweets WMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "    'Twitter W1 Score EMA(l-t)',\n",
    "    'Twitter W1 Score EMA(s-t)',\n",
    "    'Twitter W1 Score SMA(l-t)',\n",
    "    'Twitter W1 Score SMA(s-t)',\n",
    "    'Twitter W1 Score WMA(l-t)',\n",
    "    'Twitter W1 Score WMA(s-t)',\n",
    "    'VIm',\n",
    "    'Volume',\n",
    "    'W1 Score']\n",
    "\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     predict_y1= np.argmax(stacking_classifier.predict_proba(X_test_scaled),axis=0)\n",
    "    predict_y=  Model2.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    #PredictDF['Predicted_Label']= predict_y\n",
    "\n",
    "#     print(classification_report(y_test, predict_y))   \n",
    "\n",
    "    testy_predThreshold = np.where(predict_y > UpperThreshold, 1,np.where(predict_y < LowerThresshold, 0,2))\n",
    "    testy_predThreshold = testy_predThreshold.squeeze()\n",
    "    dataset = pd.DataFrame({'Y_TEST': y_test, 'Y_PREDICTED': testy_predThreshold}, columns=['Y_TEST', 'Y_PREDICTED'])\n",
    "    dataset2 = dataset.drop(dataset[dataset.Y_PREDICTED == 2].index)\n",
    "   \n",
    "    try:\n",
    "#         LTSMaccuracy = accuracy_score(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values)\n",
    "#         LTSM_RESULTS.append(LTSMaccuracy)\n",
    "    \n",
    "#         # Print classification report\n",
    "        print(classification_report(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "        print(confusion_matrix(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "    except:\n",
    "        print(\"No values\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad7d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.41      0.48      1922\n",
      "         1.0       0.56      0.71      0.62      1992\n",
      "\n",
      "    accuracy                           0.56      3914\n",
      "   macro avg       0.57      0.56      0.55      3914\n",
      "weighted avg       0.57      0.56      0.55      3914\n",
      "\n",
      "[[ 796 1126]\n",
      " [ 584 1408]]\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def binary(value):\n",
    "      if value > 0:\n",
    "        return 1\n",
    "      else:\n",
    "        return 0\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.55\n",
    "LowerThresshold = 0.45\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "    \n",
    "    feature_names_JMJ = [\n",
    "    '# of Hourly Trades SMA(l-t)',\n",
    "    '# of Hourly Trades SMA(s-t)',\n",
    "    '# of Hourly Trades WMA(l-t)',\n",
    "    '14 period MFI',\n",
    "    '14 period STOCH %K',\n",
    "    '20 period CCI',\n",
    "    '2x_retweets_+_favorites',\n",
    "    '3MovingAverage',\n",
    "    'BinaryJMJ_3HMoving_averages',\n",
    "    'BinaryJMJ_5HMoving_averages',\n",
    "    'BinaryMFV',\n",
    "    'BinaryOpen',\n",
    "    'BinaryQuote Asset Volume',\n",
    "    'BinaryVolume',\n",
    "    'Bitcoin_Google_Trend_Score',\n",
    "    'BTC_Google_Trend_Score',\n",
    "    'Bull_ratio',\n",
    "    'ema5',\n",
    "    'ema50',\n",
    "    'favorites',\n",
    "    'followers_following_ratio',\n",
    "    'following',\n",
    "    'Historically Optimal EMA(l-t)',\n",
    "    'Historically Optimal SMA(s-t)',\n",
    "    'Historically Optimal WMA(s-t)',\n",
    "    'MFV',\n",
    "    'Mkt Sentiment',\n",
    "    'normVol',\n",
    "    'Number of Trades',\n",
    "    'OBV',\n",
    "    'polarity',\n",
    "    'Quote Asset Volume',\n",
    "    'Quote Asset Volume SMA(l-t)',\n",
    "    'Quote Asset Volume SMA(s-t)',\n",
    "    'retweets',\n",
    "    'ROC',\n",
    "    'TB Base Volume',\n",
    "    'TB Base Volume EMA(l-t)',\n",
    "    'TB Base Volume EMA(s-t)',\n",
    "    'TB Base Volume SMA(l-t)',\n",
    "    'TB Base Volume WMA(l-t)',\n",
    "    'TB Base Volume WMA(s-t)',\n",
    "    'TB Quote Volume',\n",
    "    'TB Quote Volume WMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "    'Twitter Hourly Favorites EMA(s-t)',\n",
    "    'Twitter Hourly Favorites WMA(l-t)',\n",
    "    'Twitter Hourly Favorites WMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure WMA(l-t)' ,\n",
    "    'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "    'Twitter Hourly Retweets EMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(s-t)',\n",
    "    'Twitter Hourly Retweets WMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "    'Twitter W1 Score EMA(l-t)',\n",
    "    'Twitter W1 Score EMA(s-t)',\n",
    "    'Twitter W1 Score SMA(l-t)',\n",
    "    'Twitter W1 Score SMA(s-t)',\n",
    "    'Twitter W1 Score WMA(l-t)',\n",
    "    'Twitter W1 Score WMA(s-t)',\n",
    "    'VIm',\n",
    "    'Volume',\n",
    "    'W1 Score']\n",
    "\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     predict_y1= np.argmax(stacking_classifier.predict_proba(X_test_scaled),axis=0)\n",
    "    predict_y=  Model2.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    #PredictDF['Predicted_Label']= predict_y\n",
    "\n",
    "#     print(classification_report(y_test, predict_y))   \n",
    "\n",
    "    testy_predThreshold = np.where(predict_y > UpperThreshold, 1,np.where(predict_y < LowerThresshold, 0,2))\n",
    "    testy_predThreshold = testy_predThreshold.squeeze()\n",
    "    dataset = pd.DataFrame({'Y_TEST': y_test, 'Y_PREDICTED': testy_predThreshold}, columns=['Y_TEST', 'Y_PREDICTED'])\n",
    "    dataset2 = dataset.drop(dataset[dataset.Y_PREDICTED == 2].index)\n",
    "   \n",
    "    try:\n",
    "#         LTSMaccuracy = accuracy_score(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values)\n",
    "#         LTSM_RESULTS.append(LTSMaccuracy)\n",
    "    \n",
    "#         # Print classification report\n",
    "        print(classification_report(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "        print(confusion_matrix(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "    except:\n",
    "        print(\"No values\")\n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86198c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78d47b50",
   "metadata": {},
   "source": [
    "### Exporting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d9f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def binary(value):\n",
    "      if value > 0:\n",
    "        return 1\n",
    "      else:\n",
    "        return 0\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.5\n",
    "LowerThresshold = 0.5\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "    \n",
    "    feature_names_JMJ = [\n",
    "    '# of Hourly Trades SMA(l-t)',\n",
    "    '# of Hourly Trades SMA(s-t)',\n",
    "    '# of Hourly Trades WMA(l-t)',\n",
    "    '14 period MFI',\n",
    "    '14 period STOCH %K',\n",
    "    '20 period CCI',\n",
    "    '2x_retweets_+_favorites',\n",
    "    '3MovingAverage',\n",
    "    'BinaryJMJ_3HMoving_averages',\n",
    "    'BinaryJMJ_5HMoving_averages',\n",
    "    'BinaryMFV',\n",
    "    'BinaryOpen',\n",
    "    'BinaryQuote Asset Volume',\n",
    "    'BinaryVolume',\n",
    "    'Bitcoin_Google_Trend_Score',\n",
    "    'BTC_Google_Trend_Score',\n",
    "    'Bull_ratio',\n",
    "    'ema5',\n",
    "    'ema50',\n",
    "    'favorites',\n",
    "    'followers_following_ratio',\n",
    "    'following',\n",
    "    'Historically Optimal EMA(l-t)',\n",
    "    'Historically Optimal SMA(s-t)',\n",
    "    'Historically Optimal WMA(s-t)',\n",
    "    'MFV',\n",
    "    'Mkt Sentiment',\n",
    "    'normVol',\n",
    "    'Number of Trades',\n",
    "    'OBV',\n",
    "    'polarity',\n",
    "    'Quote Asset Volume',\n",
    "    'Quote Asset Volume SMA(l-t)',\n",
    "    'Quote Asset Volume SMA(s-t)',\n",
    "    'retweets',\n",
    "    'ROC',\n",
    "    'TB Base Volume',\n",
    "    'TB Base Volume EMA(l-t)',\n",
    "    'TB Base Volume EMA(s-t)',\n",
    "    'TB Base Volume SMA(l-t)',\n",
    "    'TB Base Volume WMA(l-t)',\n",
    "    'TB Base Volume WMA(s-t)',\n",
    "    'TB Quote Volume',\n",
    "    'TB Quote Volume WMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "    'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "    'Twitter Hourly Favorites EMA(s-t)',\n",
    "    'Twitter Hourly Favorites WMA(l-t)',\n",
    "    'Twitter Hourly Favorites WMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Follower Exposure WMA(l-t)' ,\n",
    "    'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "    'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "    'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "    'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "    'Twitter Hourly Retweets EMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(l-t)',\n",
    "    'Twitter Hourly Retweets SMA(s-t)',\n",
    "    'Twitter Hourly Retweets WMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "    'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "    'Twitter W1 Score EMA(l-t)',\n",
    "    'Twitter W1 Score EMA(s-t)',\n",
    "    'Twitter W1 Score SMA(l-t)',\n",
    "    'Twitter W1 Score SMA(s-t)',\n",
    "    'Twitter W1 Score WMA(l-t)',\n",
    "    'Twitter W1 Score WMA(s-t)',\n",
    "    'VIm',\n",
    "    'Volume',\n",
    "    'W1 Score']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     predict_y1= np.argmax(stacking_classifier.predict_proba(X_test_scaled),axis=0)\n",
    "    #predict_y=  Model2.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    PredictDF['Prediction']= Model2.predict_proba(X_test_scaled)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d875d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.001, n_estimators=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lda</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lr',\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               ('abc',\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               ('lda', LinearDiscriminantAnalysis()),\n",
       "                               ('GBC',\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=LogisticRegression(C=0.01, max_iter=1000),\n",
       "                   passthrough=True, stack_method='predict_proba')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e22440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>2x_retweets_+_favorites</th>\n",
       "      <th>polarity</th>\n",
       "      <th>W1 Score</th>\n",
       "      <th>Bull_ratio</th>\n",
       "      <th>W Score With Bull Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>BinaryOBV</th>\n",
       "      <th>Binary20 period CCI</th>\n",
       "      <th>Binary14 period EMV</th>\n",
       "      <th>BinaryVIm</th>\n",
       "      <th>BinaryVIp</th>\n",
       "      <th>Binaryema50</th>\n",
       "      <th>Binaryema21</th>\n",
       "      <th>Binaryema15</th>\n",
       "      <th>Binaryema5</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.797619</td>\n",
       "      <td>0.745238</td>\n",
       "      <td>16514.150000</td>\n",
       "      <td>1498.323810</td>\n",
       "      <td>63.299076</td>\n",
       "      <td>11.288095</td>\n",
       "      <td>0.113520</td>\n",
       "      <td>0.128081</td>\n",
       "      <td>4.256410</td>\n",
       "      <td>0.545164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39.326190</td>\n",
       "      <td>3.390476</td>\n",
       "      <td>16099.623810</td>\n",
       "      <td>1672.185714</td>\n",
       "      <td>110.504489</td>\n",
       "      <td>46.107143</td>\n",
       "      <td>0.087327</td>\n",
       "      <td>0.253405</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.369048</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11057.442857</td>\n",
       "      <td>1828.021429</td>\n",
       "      <td>133.780075</td>\n",
       "      <td>6.469048</td>\n",
       "      <td>0.093584</td>\n",
       "      <td>0.222649</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>0.545491</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.495238</td>\n",
       "      <td>1.890476</td>\n",
       "      <td>25029.171429</td>\n",
       "      <td>1882.980952</td>\n",
       "      <td>662.631886</td>\n",
       "      <td>18.276190</td>\n",
       "      <td>0.090903</td>\n",
       "      <td>0.173174</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.432936</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.329545</td>\n",
       "      <td>1.281818</td>\n",
       "      <td>22107.427273</td>\n",
       "      <td>2018.227273</td>\n",
       "      <td>479.791704</td>\n",
       "      <td>15.893182</td>\n",
       "      <td>0.095774</td>\n",
       "      <td>0.263250</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>0.893952</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>10.030952</td>\n",
       "      <td>2.557143</td>\n",
       "      <td>12561.900000</td>\n",
       "      <td>906.071429</td>\n",
       "      <td>406.088057</td>\n",
       "      <td>15.145238</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.365355</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>1.120422</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>9.507143</td>\n",
       "      <td>3.530952</td>\n",
       "      <td>10695.850000</td>\n",
       "      <td>805.514286</td>\n",
       "      <td>264.229345</td>\n",
       "      <td>16.569048</td>\n",
       "      <td>0.075146</td>\n",
       "      <td>0.250643</td>\n",
       "      <td>2.518519</td>\n",
       "      <td>0.631248</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.402381</td>\n",
       "      <td>22596.990476</td>\n",
       "      <td>846.535714</td>\n",
       "      <td>217.348828</td>\n",
       "      <td>26.761905</td>\n",
       "      <td>0.104180</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>1.187930</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>4.788095</td>\n",
       "      <td>1.021429</td>\n",
       "      <td>21378.707143</td>\n",
       "      <td>730.971429</td>\n",
       "      <td>172.471290</td>\n",
       "      <td>6.830952</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.310215</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>1.295602</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>10.600000</td>\n",
       "      <td>1.764286</td>\n",
       "      <td>15495.466667</td>\n",
       "      <td>663.738095</td>\n",
       "      <td>170.085989</td>\n",
       "      <td>14.128571</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>0.206627</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.671536</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7254 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      favorites  retweets  number_of_followers    following  \\\n",
       "14     9.797619  0.745238         16514.150000  1498.323810   \n",
       "15    39.326190  3.390476         16099.623810  1672.185714   \n",
       "16     5.369048  0.550000         11057.442857  1828.021429   \n",
       "17    14.495238  1.890476         25029.171429  1882.980952   \n",
       "18    13.329545  1.281818         22107.427273  2018.227273   \n",
       "...         ...       ...                  ...          ...   \n",
       "7263  10.030952  2.557143         12561.900000   906.071429   \n",
       "7264   9.507143  3.530952         10695.850000   805.514286   \n",
       "7265  17.957143  4.402381         22596.990476   846.535714   \n",
       "7266   4.788095  1.021429         21378.707143   730.971429   \n",
       "7267  10.600000  1.764286         15495.466667   663.738095   \n",
       "\n",
       "      followers_following_ratio  2x_retweets_+_favorites  polarity  W1 Score  \\\n",
       "14                    63.299076                11.288095  0.113520  0.128081   \n",
       "15                   110.504489                46.107143  0.087327  0.253405   \n",
       "16                   133.780075                 6.469048  0.093584  0.222649   \n",
       "17                   662.631886                18.276190  0.090903  0.173174   \n",
       "18                   479.791704                15.893182  0.095774  0.263250   \n",
       "...                         ...                      ...       ...       ...   \n",
       "7263                 406.088057                15.145238  0.094200  0.365355   \n",
       "7264                 264.229345                16.569048  0.075146  0.250643   \n",
       "7265                 217.348828                26.761905  0.104180  0.403896   \n",
       "7266                 172.471290                 6.830952  0.097456  0.310215   \n",
       "7267                 170.085989                14.128571  0.078864  0.206627   \n",
       "\n",
       "      Bull_ratio  W Score With Bull Ratio  ...  BinaryOBV  \\\n",
       "14      4.256410                 0.545164  ...          0   \n",
       "15      2.500000                 0.633513  ...          0   \n",
       "16      2.450000                 0.545491  ...          0   \n",
       "17      2.500000                 0.432936  ...          1   \n",
       "18      3.395833                 0.893952  ...          1   \n",
       "...          ...                      ...  ...        ...   \n",
       "7263    3.066667                 1.120422  ...          1   \n",
       "7264    2.518519                 0.631248  ...          0   \n",
       "7265    2.941176                 1.187930  ...          0   \n",
       "7266    4.176471                 1.295602  ...          1   \n",
       "7267    3.250000                 0.671536  ...          0   \n",
       "\n",
       "      Binary20 period CCI  Binary14 period EMV  BinaryVIm  BinaryVIp  \\\n",
       "14                      1                    0          0          0   \n",
       "15                      0                    0          1          0   \n",
       "16                      1                    0          1          0   \n",
       "17                      1                    1          0          1   \n",
       "18                      1                    1          0          1   \n",
       "...                   ...                  ...        ...        ...   \n",
       "7263                    1                    1          0          1   \n",
       "7264                    1                    1          0          1   \n",
       "7265                    0                    0          1          1   \n",
       "7266                    1                    0          1          0   \n",
       "7267                    1                    0          1          0   \n",
       "\n",
       "      Binaryema50  Binaryema21  Binaryema15  Binaryema5  Prediction  \n",
       "14              0            0            0           0    0.635768  \n",
       "15              0            0            0           0    0.639907  \n",
       "16              0            0            0           1    0.626424  \n",
       "17              1            1            1           1    0.595970  \n",
       "18              1            1            1           1    0.462729  \n",
       "...           ...          ...          ...         ...         ...  \n",
       "7263            1            1            1           1    0.644039  \n",
       "7264            0            0            0           1    0.626921  \n",
       "7265            0            1            1           1    0.643698  \n",
       "7266            1            1            1           1    0.510287  \n",
       "7267            0            0            0           0    0.623387  \n",
       "\n",
       "[7254 rows x 179 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ed7e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictDF.to_csv('predictions/PriotyFeatures_StackingPrediction_LR_ABC_LDA_GBC_to_LR.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
