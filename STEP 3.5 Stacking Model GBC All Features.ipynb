{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709bba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from finta import TA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import optimizers, metrics\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947dd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "# Df_hourly_merge = pd.read_csv('assets/PCHourly2019202_ActualLabel.csv')\n",
    "Df_hourly_merge = pd.read_csv('assets/MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv')\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "Indicatordata = _exponential_smooth(Df_hourly_merge[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "Df_hourly_merge2 = pd.merge(Df_hourly_merge, Indicatordatafinal, left_index=True, right_index=True)\n",
    "\n",
    "Df_hourly_merge2 = Df_hourly_merge2.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binary(value):\n",
    "  if value > 0:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "       'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "       'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "       'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "       '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "for column in columns: \n",
    "    Df_hourly_merge2['Binary{}'.format(column)]  = (Df_hourly_merge2[column] - Df_hourly_merge2[column].shift(1)).apply(binary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca380c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25503"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Df_hourly_merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da43cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>2x_retweets_+_favorites</th>\n",
       "      <th>polarity</th>\n",
       "      <th>W1 Score</th>\n",
       "      <th>Bull_ratio</th>\n",
       "      <th>W Score With Bull Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>BinaryROC</th>\n",
       "      <th>BinaryOBV</th>\n",
       "      <th>Binary20 period CCI</th>\n",
       "      <th>Binary14 period EMV</th>\n",
       "      <th>BinaryVIm</th>\n",
       "      <th>BinaryVIp</th>\n",
       "      <th>Binaryema50</th>\n",
       "      <th>Binaryema21</th>\n",
       "      <th>Binaryema15</th>\n",
       "      <th>Binaryema5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.517857</td>\n",
       "      <td>1.276786</td>\n",
       "      <td>10592.354167</td>\n",
       "      <td>1652.068452</td>\n",
       "      <td>45.605159</td>\n",
       "      <td>9.071429</td>\n",
       "      <td>0.124241</td>\n",
       "      <td>0.264455</td>\n",
       "      <td>3.275000</td>\n",
       "      <td>0.866089</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.685230</td>\n",
       "      <td>0.479419</td>\n",
       "      <td>14341.610169</td>\n",
       "      <td>1852.799031</td>\n",
       "      <td>74.444302</td>\n",
       "      <td>3.644068</td>\n",
       "      <td>0.067950</td>\n",
       "      <td>0.097316</td>\n",
       "      <td>3.342105</td>\n",
       "      <td>0.325240</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.138107</td>\n",
       "      <td>0.670077</td>\n",
       "      <td>21769.074169</td>\n",
       "      <td>2449.731458</td>\n",
       "      <td>68.571009</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>0.120056</td>\n",
       "      <td>0.144203</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>0.882520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.916462</td>\n",
       "      <td>0.670762</td>\n",
       "      <td>36958.090909</td>\n",
       "      <td>2790.968059</td>\n",
       "      <td>100.500076</td>\n",
       "      <td>3.257985</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.110483</td>\n",
       "      <td>5.964286</td>\n",
       "      <td>0.658951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.339394</td>\n",
       "      <td>0.921212</td>\n",
       "      <td>13345.724242</td>\n",
       "      <td>3208.639394</td>\n",
       "      <td>66.105667</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>0.136780</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>4.607143</td>\n",
       "      <td>0.920041</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>5.783333</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>12129.000000</td>\n",
       "      <td>1975.276190</td>\n",
       "      <td>108.150291</td>\n",
       "      <td>7.102381</td>\n",
       "      <td>0.077630</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>3.022222</td>\n",
       "      <td>0.237728</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25499</th>\n",
       "      <td>3.011905</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>14180.595238</td>\n",
       "      <td>1765.121429</td>\n",
       "      <td>31.755382</td>\n",
       "      <td>3.797619</td>\n",
       "      <td>0.095683</td>\n",
       "      <td>0.135134</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>0.578073</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25500</th>\n",
       "      <td>14.400000</td>\n",
       "      <td>2.407143</td>\n",
       "      <td>16161.992857</td>\n",
       "      <td>2084.061905</td>\n",
       "      <td>182.260151</td>\n",
       "      <td>19.214286</td>\n",
       "      <td>0.082271</td>\n",
       "      <td>0.107210</td>\n",
       "      <td>3.648649</td>\n",
       "      <td>0.391172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25501</th>\n",
       "      <td>21.570806</td>\n",
       "      <td>3.270153</td>\n",
       "      <td>11254.296296</td>\n",
       "      <td>1814.954248</td>\n",
       "      <td>428.484448</td>\n",
       "      <td>28.111111</td>\n",
       "      <td>0.070485</td>\n",
       "      <td>0.165014</td>\n",
       "      <td>1.887324</td>\n",
       "      <td>0.311435</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25502</th>\n",
       "      <td>7.505967</td>\n",
       "      <td>0.878282</td>\n",
       "      <td>10556.818616</td>\n",
       "      <td>2143.973747</td>\n",
       "      <td>140.745063</td>\n",
       "      <td>9.262530</td>\n",
       "      <td>0.079407</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>3.945946</td>\n",
       "      <td>0.534052</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25503 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorites  retweets  number_of_followers    following  \\\n",
       "0       6.517857  1.276786         10592.354167  1652.068452   \n",
       "1       2.685230  0.479419         14341.610169  1852.799031   \n",
       "2       2.138107  0.670077         21769.074169  2449.731458   \n",
       "3       1.916462  0.670762         36958.090909  2790.968059   \n",
       "4       4.339394  0.921212         13345.724242  3208.639394   \n",
       "...          ...       ...                  ...          ...   \n",
       "25498   5.783333  0.659524         12129.000000  1975.276190   \n",
       "25499   3.011905  0.392857         14180.595238  1765.121429   \n",
       "25500  14.400000  2.407143         16161.992857  2084.061905   \n",
       "25501  21.570806  3.270153         11254.296296  1814.954248   \n",
       "25502   7.505967  0.878282         10556.818616  2143.973747   \n",
       "\n",
       "       followers_following_ratio  2x_retweets_+_favorites  polarity  W1 Score  \\\n",
       "0                      45.605159                 9.071429  0.124241  0.264455   \n",
       "1                      74.444302                 3.644068  0.067950  0.097316   \n",
       "2                      68.571009                 3.478261  0.120056  0.144203   \n",
       "3                     100.500076                 3.257985  0.143717  0.110483   \n",
       "4                      66.105667                 6.181818  0.136780  0.199699   \n",
       "...                          ...                      ...       ...       ...   \n",
       "25498                 108.150291                 7.102381  0.077630  0.078660   \n",
       "25499                  31.755382                 3.797619  0.095683  0.135134   \n",
       "25500                 182.260151                19.214286  0.082271  0.107210   \n",
       "25501                 428.484448                28.111111  0.070485  0.165014   \n",
       "25502                 140.745063                 9.262530  0.079407  0.135342   \n",
       "\n",
       "       Bull_ratio  W Score With Bull Ratio  ...  BinaryROC  BinaryOBV  \\\n",
       "0        3.275000                 0.866089  ...          0          0   \n",
       "1        3.342105                 0.325240  ...          0          0   \n",
       "2        6.120000                 0.882520  ...          0          0   \n",
       "3        5.964286                 0.658951  ...          0          0   \n",
       "4        4.607143                 0.920041  ...          0          0   \n",
       "...           ...                      ...  ...        ...        ...   \n",
       "25498    3.022222                 0.237728  ...          0          0   \n",
       "25499    4.277778                 0.578073  ...          0          0   \n",
       "25500    3.648649                 0.391172  ...          0          0   \n",
       "25501    1.887324                 0.311435  ...          0          1   \n",
       "25502    3.945946                 0.534052  ...          0          0   \n",
       "\n",
       "       Binary20 period CCI  Binary14 period EMV  BinaryVIm  BinaryVIp  \\\n",
       "0                        0                    0          0          0   \n",
       "1                        0                    0          0          0   \n",
       "2                        0                    0          0          0   \n",
       "3                        0                    0          0          0   \n",
       "4                        1                    0          0          0   \n",
       "...                    ...                  ...        ...        ...   \n",
       "25498                    1                    1          0          1   \n",
       "25499                    0                    1          0          1   \n",
       "25500                    0                    0          1          0   \n",
       "25501                    0                    0          1          0   \n",
       "25502                    0                    0          1          0   \n",
       "\n",
       "       Binaryema50  Binaryema21  Binaryema15  Binaryema5  \n",
       "0                0            0            0           0  \n",
       "1                1            1            1           1  \n",
       "2                0            0            0           0  \n",
       "3                0            0            0           0  \n",
       "4                0            0            0           0  \n",
       "...            ...          ...          ...         ...  \n",
       "25498            0            0            0           0  \n",
       "25499            0            0            0           0  \n",
       "25500            0            0            0           0  \n",
       "25501            1            1            1           1  \n",
       "25502            0            0            0           0  \n",
       "\n",
       "[25503 rows x 178 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_hourly_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8825a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['favorites', 'retweets', 'number_of_followers', 'following',\n",
       "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
       "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
       "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
       "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
       "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
       "       'JMJ_5HMoving_averages', 'Actual_Label',\n",
       "       'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
       "       'Mkt Sentiment', 'Crypto Sentiment',\n",
       "       'Historically Optimal SMA(s-t)', 'Historically Optimal SMA(l-t)',\n",
       "       'Historically Optimal WMA(s-t)', 'Historically Optimal WMA(l-t)',\n",
       "       'Historically Optimal EMA(s-t)', 'Historically Optimal EMA(l-t)',\n",
       "       'Twitter Hourly Favorites SMA(s-t)',\n",
       "       'Twitter Hourly Favorites SMA(l-t)',\n",
       "       'Twitter Hourly Favorites WMA(s-t)',\n",
       "       'Twitter Hourly Favorites WMA(l-t)',\n",
       "       'Twitter Hourly Favorites EMA(s-t)',\n",
       "       'Twitter Hourly Favorites EMA(l-t)',\n",
       "       'Twitter Hourly Retweets SMA(s-t)',\n",
       "       'Twitter Hourly Retweets SMA(l-t)',\n",
       "       'Twitter Hourly Retweets WMA(s-t)',\n",
       "       'Twitter Hourly Retweets WMA(l-t)',\n",
       "       'Twitter Hourly Retweets EMA(s-t)',\n",
       "       'Twitter Hourly Retweets EMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
       "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
       "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
       "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
       "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
       "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
       "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
       "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
       "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
       "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
       "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
       "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
       "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
       "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
       "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
       "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
       "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
       "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
       "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
       "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
       "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
       "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
       "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
       "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
       "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
       "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
       "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
       "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
       "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
       "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
       "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
       "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
       "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
       "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
       "       'Binaryema5'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_hourly_merge2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b89263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = Df_hourly_merge2\n",
    "data = data.dropna()\n",
    "\n",
    "feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "X_JMJ = data[feature_names_JMJ]\n",
    "y_JMJ = data['Actual_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71371fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names_JMJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b15bc",
   "metadata": {},
   "source": [
    "## BASE ESTIMATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce48f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _LogisticRegression(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new random forest classifier\n",
    "    #et = ExtraTreesClassifier()\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_lr = {\n",
    "                    'C': [0.01, 0.1, 1, 10, 100], \n",
    "                    \"penalty\":['l2'],\n",
    "                    'solver': ['lbfgs'],\n",
    "                    'max_iter':[1000]\n",
    "        \n",
    "        \n",
    "        \n",
    "                    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    lr_gs = GridSearchCV(lr, params_lr, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    lr_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    lr_best = lr_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(lr_gs.best_params_)\n",
    "    \n",
    "    prediction = lr_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return lr_best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aaaebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_AdaBoostClassifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new random forest classifier\n",
    "    abc = AdaBoostClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_abc =  {\n",
    "                'n_estimators': [20, 50, 70, 100],\n",
    "                'learning_rate' : [0.001, 0.01, 0.1, 0.2]\n",
    "                }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    abc_gs = GridSearchCV(abc, params_abc, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    abc_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    abc_best = abc_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(abc_gs.best_params_)\n",
    "    \n",
    "    prediction = abc_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return abc_best\n",
    "    \n",
    "# abc_model = _train_AdaBoostClassifier(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d99641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _train_LDA(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    \n",
    "    param_lda = {\n",
    "                'solver': ['svd', 'lsqr', 'eigen']\n",
    "                                  \n",
    "                 }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    lda_gs = GridSearchCV(lda, param_lda, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    lda_gs.fit(X_train, y_train)\n",
    "              \n",
    "    # Save best model\n",
    "    lda_best = lda_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(lda_gs.best_params_)\n",
    "    \n",
    "    prediction = lda_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return lda_best\n",
    "    \n",
    "    \n",
    "# lda_model = _train_LDA(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4fe796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _GradientBoosingClassifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a ne\n",
    "    GBC = GradientBoostingClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_nnclf = {\n",
    "    \"loss\":[\"log_loss\"],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "#     \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[0.5, 1.0],\n",
    "    \"n_estimators\":[100]\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    GBC_gs = GridSearchCV(GBC, params_nnclf, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    GBC_gs.fit(X_train, y_train)\n",
    "#     GBC.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Save best model\n",
    "    GBC_best = GBC_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(GBC_gs.best_params_)\n",
    "    \n",
    "    prediction = GBC_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return GBC_best\n",
    "    \n",
    "# GBC_model = _GradientBoosingClassifier(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75264452",
   "metadata": {},
   "source": [
    "## FINAL MODEL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11fdf156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2316 2317 2318] [2319 2320 2321 ... 4633 4634 4635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.35      0.42      1084\n",
      "         1.0       0.57      0.75      0.64      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.55      0.53      2317\n",
      "weighted avg       0.56      0.56      0.54      2317\n",
      "\n",
      "[[375 709]\n",
      " [310 923]]\n",
      "{'learning_rate': 0.01, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.56      0.54      1084\n",
      "         1.0       0.58      0.53      0.55      1233\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[612 472]\n",
      " [581 652]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 27 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.52480077 0.52480077        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.25      0.33      1084\n",
      "         1.0       0.53      0.75      0.62      1233\n",
      "\n",
      "    accuracy                           0.52      2317\n",
      "   macro avg       0.50      0.50      0.47      2317\n",
      "weighted avg       0.50      0.52      0.48      2317\n",
      "\n",
      "[[270 814]\n",
      " [306 927]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.43      0.48      1084\n",
      "         1.0       0.58      0.68      0.63      1233\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.57      0.56      2317\n",
      "\n",
      "[[466 618]\n",
      " [389 844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.37      0.44      1084\n",
      "         1.0       0.57      0.72      0.63      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.56      0.54      2317\n",
      "\n",
      "[[403 681]\n",
      " [347 886]]\n",
      "ABC Accuracy = 0.5455330168321105 , LDA Accuracy = 0.5166163141993958 , LR Accuracy = 0.5602071644367717 , GBC Accuracy = 0.5653862753560639 , LTSM Accuracy = 0.5563228312473025\n",
      " \n",
      "[   0    1    2 ... 4633 4634 4635] [4636 4637 4638 ... 6950 6951 6952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.33      0.42      1178\n",
      "         1.0       0.53      0.77      0.63      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.56      0.55      0.53      2317\n",
      "weighted avg       0.56      0.55      0.52      2317\n",
      "\n",
      "[[386 792]\n",
      " [257 882]]\n",
      "{'learning_rate': 0.01, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.47      0.53      1178\n",
      "         1.0       0.55      0.68      0.61      1139\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.58      0.57      0.57      2317\n",
      "weighted avg       0.58      0.57      0.57      2317\n",
      "\n",
      "[[553 625]\n",
      " [370 769]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.55004255 0.5476693         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.04      0.08      1178\n",
      "         1.0       0.50      0.98      0.66      1139\n",
      "\n",
      "    accuracy                           0.50      2317\n",
      "   macro avg       0.57      0.51      0.37      2317\n",
      "weighted avg       0.57      0.50      0.36      2317\n",
      "\n",
      "[[  48 1130]\n",
      " [  27 1112]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.28      0.38      1178\n",
      "         1.0       0.52      0.82      0.64      1139\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.57      0.55      0.51      2317\n",
      "weighted avg       0.57      0.54      0.51      2317\n",
      "\n",
      "[[328 850]\n",
      " [206 933]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.25      0.35      1178\n",
      "         1.0       0.52      0.84      0.64      1139\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.57      0.54      0.50      2317\n",
      "weighted avg       0.57      0.54      0.49      2317\n",
      "\n",
      "[[290 888]\n",
      " [182 957]]\n",
      "ABC Accuracy = 0.570565386275356 , LDA Accuracy = 0.5006473888649116 , LR Accuracy = 0.5472593871385412 , GBC Accuracy = 0.5442382391022874 , LTSM Accuracy = 0.5381959430297799\n",
      " \n",
      "[   0    1    2 ... 6950 6951 6952] [6953 6954 6955 ... 9267 9268 9269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.52      0.54      1144\n",
      "         1.0       0.57      0.63      0.60      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[590 554]\n",
      " [432 741]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.59      0.58      1144\n",
      "         1.0       0.58      0.55      0.57      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[675 469]\n",
      " [522 651]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 27 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.49876917 0.49920103        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.61      0.58      1144\n",
      "         1.0       0.58      0.53      0.56      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[695 449]\n",
      " [550 623]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.58      0.57      1144\n",
      "         1.0       0.58      0.57      0.57      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[659 485]\n",
      " [509 664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.57      0.57      1144\n",
      "         1.0       0.58      0.58      0.58      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[648 496]\n",
      " [490 683]]\n",
      "ABC Accuracy = 0.5722917565817868 , LDA Accuracy = 0.5688390159689254 , LR Accuracy = 0.5744497194648253 , GBC Accuracy = 0.5709969788519638 , LTSM Accuracy = 0.5744497194648253\n",
      " \n",
      "[   0    1    2 ... 9267 9268 9269] [ 9270  9271  9272 ... 11584 11585 11586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.54      1127\n",
      "         1.0       0.55      0.53      0.54      1190\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[623 504]\n",
      " [564 626]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.61      0.56      1127\n",
      "         1.0       0.57      0.48      0.52      1190\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[685 442]\n",
      " [613 577]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.52556634 0.52535059        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.53      0.53      1127\n",
      "         1.0       0.56      0.56      0.56      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[600 527]\n",
      " [524 666]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.52      0.53      1127\n",
      "         1.0       0.56      0.57      0.57      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[588 539]\n",
      " [509 681]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.60      0.57      1127\n",
      "         1.0       0.57      0.49      0.53      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[681 446]\n",
      " [602 588]]\n",
      "ABC Accuracy = 0.5446698316788952 , LDA Accuracy = 0.5463962019853259 , LR Accuracy = 0.5390591281829953 , GBC Accuracy = 0.5476909797151489 , LTSM Accuracy = 0.5476909797151489\n",
      " \n",
      "[    0     1     2 ... 11584 11585 11586] [11587 11588 11589 ... 13901 13902 13903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.58      0.56      1125\n",
      "         1.0       0.58      0.55      0.56      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[648 477]\n",
      " [542 650]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.65      0.59      1125\n",
      "         1.0       0.59      0.47      0.52      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[736 389]\n",
      " [637 555]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.53525739 0.53534371        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.67      0.59      1125\n",
      "         1.0       0.58      0.42      0.49      1192\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[757 368]\n",
      " [691 501]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.52      0.55      1125\n",
      "         1.0       0.58      0.63      0.60      1192\n",
      "\n",
      "    accuracy                           0.58      2317\n",
      "   macro avg       0.58      0.58      0.57      2317\n",
      "weighted avg       0.58      0.58      0.58      2317\n",
      "\n",
      "[[587 538]\n",
      " [442 750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.59      0.57      1125\n",
      "         1.0       0.59      0.55      0.57      1192\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[667 458]\n",
      " [537 655]]\n",
      "ABC Accuracy = 0.5571860164005179 , LDA Accuracy = 0.5429434613724644 , LR Accuracy = 0.5602071644367717 , GBC Accuracy = 0.5770392749244713 , LTSM Accuracy = 0.570565386275356\n",
      " \n",
      "[    0     1     2 ... 13901 13902 13903] [13904 13905 13906 ... 16218 16219 16220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.48      0.51      1120\n",
      "         1.0       0.56      0.60      0.58      1197\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.54      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[543 577]\n",
      " [474 723]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.62      0.57      1120\n",
      "         1.0       0.57      0.46      0.51      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[699 421]\n",
      " [647 550]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.529921   0.52984908        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.57      0.55      1120\n",
      "         1.0       0.56      0.52      0.54      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[641 479]\n",
      " [579 618]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.44      0.49      1120\n",
      "         1.0       0.55      0.65      0.60      1197\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[497 623]\n",
      " [423 774]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.95      0.64      1120\n",
      "         1.0       0.52      0.05      0.09      1197\n",
      "\n",
      "    accuracy                           0.49      2317\n",
      "   macro avg       0.50      0.50      0.37      2317\n",
      "weighted avg       0.50      0.49      0.36      2317\n",
      "\n",
      "[[1064   56]\n",
      " [1137   60]]\n",
      "ABC Accuracy = 0.5390591281829953 , LDA Accuracy = 0.543375053949072 , LR Accuracy = 0.5463962019853259 , GBC Accuracy = 0.5485541648683643 , LTSM Accuracy = 0.48511005610703495\n",
      " \n",
      "[    0     1     2 ... 16218 16219 16220] [16221 16222 16223 ... 18535 18536 18537]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.84      0.62      1100\n",
      "         1.0       0.58      0.20      0.29      1217\n",
      "\n",
      "    accuracy                           0.50      2317\n",
      "   macro avg       0.53      0.52      0.46      2317\n",
      "weighted avg       0.54      0.50      0.45      2317\n",
      "\n",
      "[[927 173]\n",
      " [978 239]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.65      0.57      1100\n",
      "         1.0       0.57      0.43      0.49      1217\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.53      0.53      2317\n",
      "\n",
      "[[714 386]\n",
      " [698 519]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.54466388 0.54491049        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.56      0.54      1100\n",
      "         1.0       0.57      0.53      0.55      1217\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[614 486]\n",
      " [575 642]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.42      0.46      1100\n",
      "         1.0       0.55      0.65      0.60      1217\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.54      0.53      2317\n",
      "\n",
      "[[460 640]\n",
      " [423 794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.43      0.47      1100\n",
      "         1.0       0.56      0.64      0.59      1217\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[478 622]\n",
      " [441 776]]\n",
      "ABC Accuracy = 0.5321536469572723 , LDA Accuracy = 0.542080276219249 , LR Accuracy = 0.5032369443245576 , GBC Accuracy = 0.5412170910660337 , LTSM Accuracy = 0.5412170910660337\n",
      " \n",
      "[    0     1     2 ... 18535 18536 18537] [18538 18539 18540 ... 20852 20853 20854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.52      0.52      1139\n",
      "         1.0       0.53      0.54      0.54      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[587 552]\n",
      " [543 635]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.58      0.55      1139\n",
      "         1.0       0.54      0.48      0.51      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[661 478]\n",
      " [608 570]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.54957383 0.54984351        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.86      0.63      1139\n",
      "         1.0       0.56      0.18      0.27      1178\n",
      "\n",
      "    accuracy                           0.51      2317\n",
      "   macro avg       0.53      0.52      0.45      2317\n",
      "weighted avg       0.53      0.51      0.45      2317\n",
      "\n",
      "[[975 164]\n",
      " [967 211]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.43      0.48      1139\n",
      "         1.0       0.53      0.63      0.58      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[492 647]\n",
      " [437 741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.52      0.52      1139\n",
      "         1.0       0.54      0.54      0.54      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[589 550]\n",
      " [537 641]]\n",
      "ABC Accuracy = 0.5312904618040569 , LDA Accuracy = 0.5118687958567113 , LR Accuracy = 0.5274061286145878 , GBC Accuracy = 0.5321536469572723 , LTSM Accuracy = 0.5308588692274493\n",
      " \n",
      "[    0     1     2 ... 20852 20853 20854] [20855 20856 20857 ... 23169 23170 23171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.43      0.47      1151\n",
      "         1.0       0.53      0.62      0.57      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.52      2317\n",
      "weighted avg       0.53      0.53      0.52      2317\n",
      "\n",
      "[[495 656]\n",
      " [440 726]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.54      1151\n",
      "         1.0       0.53      0.50      0.51      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[637 514]\n",
      " [584 582]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.54054184 0.54011029        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.87      0.64      1151\n",
      "         1.0       0.56      0.17      0.26      1166\n",
      "\n",
      "    accuracy                           0.52      2317\n",
      "   macro avg       0.53      0.52      0.45      2317\n",
      "weighted avg       0.53      0.52      0.45      2317\n",
      "\n",
      "[[1000  151]\n",
      " [ 972  194]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.39      0.45      1151\n",
      "         1.0       0.53      0.68      0.59      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.54      0.53      0.52      2317\n",
      "weighted avg       0.54      0.53      0.52      2317\n",
      "\n",
      "[[444 707]\n",
      " [375 791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.32      0.41      1151\n",
      "         1.0       0.53      0.74      0.61      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.54      0.53      0.51      2317\n",
      "weighted avg       0.54      0.53      0.51      2317\n",
      "\n",
      "[[372 779]\n",
      " [303 863]]\n",
      "ABC Accuracy = 0.5261113508847648 , LDA Accuracy = 0.5153215364695727 , LR Accuracy = 0.5269745360379802 , GBC Accuracy = 0.5330168321104877 , LTSM Accuracy = 0.5330168321104877\n",
      " \n",
      "[    0     1     2 ... 23169 23170 23171] [23172 23173 23174 ... 25486 25487 25488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.57      0.57      1166\n",
      "         1.0       0.56      0.54      0.55      1151\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[669 497]\n",
      " [530 621]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.57      0.56      1166\n",
      "         1.0       0.55      0.53      0.54      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[662 504]\n",
      " [542 609]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.53823458 0.53797562        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.46      0.51      1166\n",
      "         1.0       0.54      0.65      0.59      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.56      0.55      0.55      2317\n",
      "weighted avg       0.56      0.55      0.55      2317\n",
      "\n",
      "[[540 626]\n",
      " [408 743]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.44      0.49      1166\n",
      "         1.0       0.54      0.66      0.59      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[510 656]\n",
      " [390 761]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.43      0.49      1166\n",
      "         1.0       0.54      0.69      0.61      1151\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[498 668]\n",
      " [359 792]]\n",
      "ABC Accuracy = 0.5485541648683643 , LDA Accuracy = 0.5537332757876564 , LR Accuracy = 0.5567544238239103 , GBC Accuracy = 0.5485541648683643 , LTSM Accuracy = 0.5567544238239103\n",
      " \n",
      " \n",
      "ABC Accuracy = 0.546741476046612\n",
      "LDA Accuracy = 0.5341821320673285\n",
      "LR Accuracy = 0.5441950798446266\n",
      "GBC Accuracy = 0.5508847647820458\n",
      "LTSM Accuracy = 0.5434182132067329\n",
      " \n",
      "CPU times: total: 8h 14min 10s\n",
      "Wall time: 7h 55min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "LTSM_RESULTS = []\n",
    "abc_RESULTS = []\n",
    "lda_RESULTS = []\n",
    "lr_RESULTS =[]\n",
    "GBC_RESULTS = []\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_JMJ):\n",
    "    print(train_index, test_index)\n",
    "    \n",
    "    X_train, X_test = X_JMJ.iloc[train_index], X_JMJ.iloc[test_index]\n",
    "    y_train, y_test = y_JMJ.iloc[train_index], y_JMJ.iloc[test_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #Setting up the Base Estimators\n",
    "    lr_model = _LogisticRegression(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    abc_model = _train_AdaBoostClassifier(X_train_scaled, y_train,  X_test_scaled, y_test)\n",
    "    lda_model = _train_LDA(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    GBC_model = _GradientBoosingClassifier(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "\n",
    "    # Define the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('lr', lr_model),('abc', abc_model),('lda', lda_model), ('GBC',GBC_model)], \n",
    "        final_estimator=GBC_model,\n",
    "        cv=5,\n",
    "        passthrough=True,\n",
    "        stack_method='predict_proba'\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier on the training data\n",
    "    stacking_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = stacking_classifier.predict(X_test_scaled)\n",
    "    testy_pred = (y_pred >= 0.5).astype(int)\n",
    "    \n",
    "    abc_prediction = abc_model.predict(X_test_scaled)\n",
    "    lda_prediction = lda_model.predict(X_test_scaled)\n",
    "    lr_prediction = lr_model.predict(X_test_scaled)\n",
    "    GBC_prediction = GBC_model.predict(X_test_scaled)\n",
    "\n",
    "    \n",
    "    abc_accuracy = accuracy_score(y_test.values, abc_prediction)\n",
    "    lda_accuracy = accuracy_score(y_test.values, lda_prediction)\n",
    "    lr_accuracy = accuracy_score(y_test.values, lr_prediction)\n",
    "    GBC_accuracy = accuracy_score(y_test.values, GBC_prediction)\n",
    "    LTSMaccurary = accuracy_score (y_test, testy_pred)   \n",
    "   \n",
    "\n",
    "\n",
    "    abc_RESULTS.append(abc_accuracy)\n",
    "    lda_RESULTS.append(lda_accuracy)\n",
    "    lr_RESULTS.append(lr_accuracy)\n",
    "    GBC_RESULTS.append(GBC_accuracy)\n",
    "    LTSM_RESULTS.append(LTSMaccurary)\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, testy_pred))\n",
    "    print(confusion_matrix(y_test, testy_pred))\n",
    "    \n",
    "    print('ABC Accuracy = ' + str(abc_accuracy),', LDA Accuracy = ' + str(lda_accuracy),', LR Accuracy = ' + str(lr_accuracy),', GBC Accuracy = ' + str(GBC_accuracy),', LTSM Accuracy = ' + str(LTSMaccurary))#,GBC_accuracy, ensemble_accuracy)    \n",
    "    print(' ')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "print(' ')\n",
    "print('ABC Accuracy = ' + str( sum(abc_RESULTS) / len(abc_RESULTS)))\n",
    "print('LDA Accuracy = ' + str( sum(lda_RESULTS) / len(lda_RESULTS)))\n",
    "print('LR Accuracy = ' + str( sum(lr_RESULTS) / len(lr_RESULTS)))\n",
    "print('GBC Accuracy = ' + str( sum(GBC_RESULTS) / len(GBC_RESULTS)))\n",
    "print('LTSM Accuracy = ' + str( sum(LTSM_RESULTS) / len(LTSM_RESULTS)))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65e739e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.001, n_estimators=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lda</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lr',\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               ('abc',\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               ('lda', LinearDiscriminantAnalysis()),\n",
       "                               ('GBC',\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
       "                   passthrough=True, stack_method='predict_proba')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "585825d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(cv=5,\n",
      "                   estimators=[('lr',\n",
      "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
      "                               ('abc',\n",
      "                                AdaBoostClassifier(learning_rate=0.001,\n",
      "                                                   n_estimators=20)),\n",
      "                               ('lda', LinearDiscriminantAnalysis()),\n",
      "                               ('GBC',\n",
      "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
      "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
      "                   passthrough=True, stack_method='predict_proba')\n"
     ]
    }
   ],
   "source": [
    "print(stacking_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21bae2",
   "metadata": {},
   "source": [
    "#### SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "150d57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#saving model\n",
    "pkl_filename = 'model/Stacking_GBC_model_JT2019to2022TEST_news_google.pkl'\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(stacking_classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde49db",
   "metadata": {},
   "source": [
    "#### LOADING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = 'model/Stacking_GBC_model_JT2019to2022TEST_news_google.pkl'\n",
    "with open(pkl_filename, 'rb') as file: \n",
    "    Model2 = pickle.load(file)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfd636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4be14ad0",
   "metadata": {},
   "source": [
    "# TESTING RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4a398",
   "metadata": {},
   "source": [
    "### Testing with Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdcebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models = [Model1,abc_model, rc_model, lda_model,lr_model,GBC_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7d9b5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.24      0.34      3625\n",
      "         1.0       0.52      0.82      0.64      3629\n",
      "\n",
      "    accuracy                           0.53      7254\n",
      "   macro avg       0.55      0.53      0.49      7254\n",
      "weighted avg       0.55      0.53      0.49      7254\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "    \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    predict_y=  Model2.predict(X_test_scaled)\n",
    "    PredictDF['Predicted_Label']= predict_y\n",
    "\n",
    "    print(classification_report(y_test, predict_y))   \n",
    "    \n",
    "    # confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "    confusion_mc = confusion_matrix(PredictDF['Actual_Label'], PredictDF['Predicted_Label'])\n",
    "    df_cm = pd.DataFrame(confusion_mc, \n",
    "                         index = [i for i in range(0,2)], columns = [i for i in range(0,2)])\n",
    "\n",
    "\n",
    "    PredictDF['ValueActual'] =0\n",
    "    PredictDF['BTCValueActual'] =0\n",
    "    if PredictDF.loc[PredictDF.index[0],'Actual_Label']==0.0:\n",
    "        PredictDF.loc[PredictDF.index[0],'ValueActual']=1000\n",
    "    else:\n",
    "        PredictDF.loc[PredictDF.index[0],'BTCValueActual']=round((1000/PredictDF.loc[PredictDF.index[0],'Close']),5)\n",
    "\n",
    "\n",
    "    for current in range(1, len(PredictDF.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if PredictDF.loc[PredictDF.index[current],'Actual_Label']==0 and PredictDF.loc[PredictDF.index[previous],'BTCValueActual']==0:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual']=PredictDF.loc[PredictDF.index[previous],'ValueActual']\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Actual_Label']==1 and PredictDF.loc[PredictDF.index[previous],'ValueActual'] ==0 :\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual']= 0\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValueActual']=round(PredictDF.loc[PredictDF.index[previous],'BTCValueActual'],3)\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Actual_Label']==1:\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValueActual'] = round((PredictDF.loc[PredictDF.index[previous],'ValueActual']/PredictDF.loc[PredictDF.index[current],'Close']),5)\n",
    "        else:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual'] = round((PredictDF.loc[PredictDF.index[previous],'BTCValueActual'] *PredictDF.loc[PredictDF.index[current],'Close']),3)\n",
    "\n",
    "\n",
    "    PredictDF['ValuePredicted'] =0\n",
    "    PredictDF['BTCValuePredicted'] =0\n",
    "    if PredictDF.loc[PredictDF.index[0],'Predicted_Label']==0.0:\n",
    "        PredictDF.loc[PredictDF.index[0],'ValuePredicted']=1000\n",
    "    else:\n",
    "        PredictDF.loc[PredictDF.index[0],'BTCValuePredicted']=round((1000/PredictDF.loc[PredictDF.index[0],'Close']),5)\n",
    "\n",
    "\n",
    "    for current in range(1, len(PredictDF.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if PredictDF.loc[PredictDF.index[current],'Predicted_Label']==0 and PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted']==0:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted']=PredictDF.loc[PredictDF.index[previous],'ValuePredicted']\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Predicted_Label']==1 and PredictDF.loc[PredictDF.index[previous],'ValuePredicted'] ==0 :\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted']= 0\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValuePredicted']=round(PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted'],3)\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Predicted_Label']==1:\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValuePredicted'] = round((PredictDF.loc[PredictDF.index[previous],'ValuePredicted']/PredictDF.loc[PredictDF.index[current],'Close']),5)\n",
    "        else:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted'] = round((PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted'] *PredictDF.loc[PredictDF.index[current],'Close']),3)\n",
    "    df = PredictDF.mask(PredictDF==0).ffill().iloc[[-1]]\n",
    "    LastPredictvalue = df['ValuePredicted'].values[0]\n",
    "    LastPredictBTC = df['BTCValuePredicted'].values[0]\n",
    "    # LastPredictvalue= PredictDF['ValuePredicted'][PredictDF['ValuePredicted'].to_numpy().nonzero()[0][-1]+1]\n",
    "    # LastPredictBTC= PredictDF['BTCValuePredicted'][PredictDF['BTCValuePredicted'].to_numpy().nonzero()[0][-1]+1]\n",
    "\n",
    "    #     print('Total USD Value and BTC Benchmark Actual Label: ${:,.2f} and {:,.2f} BTC'.format (max(PredictDF['ValueActual']),max(PredictDF['BTCValueActual'])))#, )       \n",
    "    #     print('Total USD Value and BTC Benchmark Actual Label: ${:,.2f} and {:,.2f} BTC'.format (LastPredictvalue,LastPredictBTC))#, )       \n",
    "    #     print (' ')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "    plt.title('Assessment for: {}\\nAccuracy:{:.3f}\\nPrecision:{:.3f}\\nRecall:{:.3f}\\nF1:{:.3f}\\nBenchmark USD Value and BTC  ${:,.2f} and {:,.2f}\\nPredicted USD Value and BTC ${:,.2f} and {:,.2f}'.format(x, accuracy_score(PredictDF['Actual_Label'],PredictDF['Predicted_Label']),\n",
    "                                                                        precision_score(PredictDF['Actual_Label'],PredictDF['Predicted_Label']),\n",
    "                                                                                    recall_score(PredictDF['Actual_Label'], PredictDF['Predicted_Label']),\n",
    "                                                                                    f1_score(PredictDF['Actual_Label'], PredictDF['Predicted_Label']),\n",
    "                                                                                     max(PredictDF['ValueActual']),max(PredictDF['BTCValueActual']),\n",
    "                                                                                     LastPredictvalue,LastPredictBTC\n",
    "                                                                                    ))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5806d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.001, n_estimators=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lda</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lr',\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               ('abc',\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               ('lda', LinearDiscriminantAnalysis()),\n",
       "                               ('GBC',\n",
       "                                GradientBoostingClassifier(learning_rate=0.01))],\n",
       "                   final_estimator=GradientBoostingClassifier(learning_rate=0.01),\n",
       "                   passthrough=True, stack_method='predict_proba')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffcbfac",
   "metadata": {},
   "source": [
    "## Trying with Thesholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9941c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       876\n",
      "         1.0       0.54      1.00      0.70      1013\n",
      "\n",
      "    accuracy                           0.54      1889\n",
      "   macro avg       0.27      0.50      0.35      1889\n",
      "weighted avg       0.29      0.54      0.37      1889\n",
      "\n",
      "[[   0  876]\n",
      " [   0 1013]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mario\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.55\n",
    "LowerThresshold = 0.45\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "   \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     predict_y1= np.argmax(stacking_classifier.predict_proba(X_test_scaled),axis=0)\n",
    "    predict_y=  Model2.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    #PredictDF['Predicted_Label']= predict_y\n",
    "\n",
    "#     print(classification_report(y_test, predict_y))   \n",
    "\n",
    "    testy_predThreshold = np.where(predict_y > UpperThreshold, 1,np.where(predict_y < LowerThresshold, 0,2))\n",
    "    testy_predThreshold = testy_predThreshold.squeeze()\n",
    "    dataset = pd.DataFrame({'Y_TEST': y_test, 'Y_PREDICTED': testy_predThreshold}, columns=['Y_TEST', 'Y_PREDICTED'])\n",
    "    dataset2 = dataset.drop(dataset[dataset.Y_PREDICTED == 2].index)\n",
    "   \n",
    "    try:\n",
    "#         LTSMaccuracy = accuracy_score(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values)\n",
    "#         LTSM_RESULTS.append(LTSMaccuracy)\n",
    "    \n",
    "#         # Print classification report\n",
    "        print(classification_report(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "        print(confusion_matrix(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "    except:\n",
    "        print(\"No values\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af0d0a",
   "metadata": {},
   "source": [
    "### Exporting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fa4da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "\n",
    "testdata2022 ='assets/newfeatures/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.5\n",
    "LowerThresshold = 0.5\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "    \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     predict_y1= np.argmax(stacking_classifier.predict_proba(X_test_scaled),axis=0)\n",
    "    #predict_y=  Model2.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    PredictDF['Prediction']= Model2.predict_proba(X_test_scaled)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b8a1b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>2x_retweets_+_favorites</th>\n",
       "      <th>polarity</th>\n",
       "      <th>W1 Score</th>\n",
       "      <th>Bull_ratio</th>\n",
       "      <th>W Score With Bull Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>BinaryOBV</th>\n",
       "      <th>Binary20 period CCI</th>\n",
       "      <th>Binary14 period EMV</th>\n",
       "      <th>BinaryVIm</th>\n",
       "      <th>BinaryVIp</th>\n",
       "      <th>Binaryema50</th>\n",
       "      <th>Binaryema21</th>\n",
       "      <th>Binaryema15</th>\n",
       "      <th>Binaryema5</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.797619</td>\n",
       "      <td>0.745238</td>\n",
       "      <td>16514.150000</td>\n",
       "      <td>1498.323810</td>\n",
       "      <td>63.299076</td>\n",
       "      <td>11.288095</td>\n",
       "      <td>0.113520</td>\n",
       "      <td>0.128081</td>\n",
       "      <td>4.256410</td>\n",
       "      <td>0.545164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39.326190</td>\n",
       "      <td>3.390476</td>\n",
       "      <td>16099.623810</td>\n",
       "      <td>1672.185714</td>\n",
       "      <td>110.504489</td>\n",
       "      <td>46.107143</td>\n",
       "      <td>0.087327</td>\n",
       "      <td>0.253405</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.369048</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11057.442857</td>\n",
       "      <td>1828.021429</td>\n",
       "      <td>133.780075</td>\n",
       "      <td>6.469048</td>\n",
       "      <td>0.093584</td>\n",
       "      <td>0.222649</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>0.545491</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.495238</td>\n",
       "      <td>1.890476</td>\n",
       "      <td>25029.171429</td>\n",
       "      <td>1882.980952</td>\n",
       "      <td>662.631886</td>\n",
       "      <td>18.276190</td>\n",
       "      <td>0.090903</td>\n",
       "      <td>0.173174</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.432936</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.329545</td>\n",
       "      <td>1.281818</td>\n",
       "      <td>22107.427273</td>\n",
       "      <td>2018.227273</td>\n",
       "      <td>479.791704</td>\n",
       "      <td>15.893182</td>\n",
       "      <td>0.095774</td>\n",
       "      <td>0.263250</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>0.893952</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>10.030952</td>\n",
       "      <td>2.557143</td>\n",
       "      <td>12561.900000</td>\n",
       "      <td>906.071429</td>\n",
       "      <td>406.088057</td>\n",
       "      <td>15.145238</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.365355</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>1.120422</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>9.507143</td>\n",
       "      <td>3.530952</td>\n",
       "      <td>10695.850000</td>\n",
       "      <td>805.514286</td>\n",
       "      <td>264.229345</td>\n",
       "      <td>16.569048</td>\n",
       "      <td>0.075146</td>\n",
       "      <td>0.250643</td>\n",
       "      <td>2.518519</td>\n",
       "      <td>0.631248</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.402381</td>\n",
       "      <td>22596.990476</td>\n",
       "      <td>846.535714</td>\n",
       "      <td>217.348828</td>\n",
       "      <td>26.761905</td>\n",
       "      <td>0.104180</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>1.187930</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>4.788095</td>\n",
       "      <td>1.021429</td>\n",
       "      <td>21378.707143</td>\n",
       "      <td>730.971429</td>\n",
       "      <td>172.471290</td>\n",
       "      <td>6.830952</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.310215</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>1.295602</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>10.600000</td>\n",
       "      <td>1.764286</td>\n",
       "      <td>15495.466667</td>\n",
       "      <td>663.738095</td>\n",
       "      <td>170.085989</td>\n",
       "      <td>14.128571</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>0.206627</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.671536</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.551489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7254 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      favorites  retweets  number_of_followers    following  \\\n",
       "14     9.797619  0.745238         16514.150000  1498.323810   \n",
       "15    39.326190  3.390476         16099.623810  1672.185714   \n",
       "16     5.369048  0.550000         11057.442857  1828.021429   \n",
       "17    14.495238  1.890476         25029.171429  1882.980952   \n",
       "18    13.329545  1.281818         22107.427273  2018.227273   \n",
       "...         ...       ...                  ...          ...   \n",
       "7263  10.030952  2.557143         12561.900000   906.071429   \n",
       "7264   9.507143  3.530952         10695.850000   805.514286   \n",
       "7265  17.957143  4.402381         22596.990476   846.535714   \n",
       "7266   4.788095  1.021429         21378.707143   730.971429   \n",
       "7267  10.600000  1.764286         15495.466667   663.738095   \n",
       "\n",
       "      followers_following_ratio  2x_retweets_+_favorites  polarity  W1 Score  \\\n",
       "14                    63.299076                11.288095  0.113520  0.128081   \n",
       "15                   110.504489                46.107143  0.087327  0.253405   \n",
       "16                   133.780075                 6.469048  0.093584  0.222649   \n",
       "17                   662.631886                18.276190  0.090903  0.173174   \n",
       "18                   479.791704                15.893182  0.095774  0.263250   \n",
       "...                         ...                      ...       ...       ...   \n",
       "7263                 406.088057                15.145238  0.094200  0.365355   \n",
       "7264                 264.229345                16.569048  0.075146  0.250643   \n",
       "7265                 217.348828                26.761905  0.104180  0.403896   \n",
       "7266                 172.471290                 6.830952  0.097456  0.310215   \n",
       "7267                 170.085989                14.128571  0.078864  0.206627   \n",
       "\n",
       "      Bull_ratio  W Score With Bull Ratio  ...  BinaryOBV  \\\n",
       "14      4.256410                 0.545164  ...          0   \n",
       "15      2.500000                 0.633513  ...          0   \n",
       "16      2.450000                 0.545491  ...          0   \n",
       "17      2.500000                 0.432936  ...          1   \n",
       "18      3.395833                 0.893952  ...          1   \n",
       "...          ...                      ...  ...        ...   \n",
       "7263    3.066667                 1.120422  ...          1   \n",
       "7264    2.518519                 0.631248  ...          0   \n",
       "7265    2.941176                 1.187930  ...          0   \n",
       "7266    4.176471                 1.295602  ...          1   \n",
       "7267    3.250000                 0.671536  ...          0   \n",
       "\n",
       "      Binary20 period CCI  Binary14 period EMV  BinaryVIm  BinaryVIp  \\\n",
       "14                      1                    0          0          0   \n",
       "15                      0                    0          1          0   \n",
       "16                      1                    0          1          0   \n",
       "17                      1                    1          0          1   \n",
       "18                      1                    1          0          1   \n",
       "...                   ...                  ...        ...        ...   \n",
       "7263                    1                    1          0          1   \n",
       "7264                    1                    1          0          1   \n",
       "7265                    0                    0          1          1   \n",
       "7266                    1                    0          1          0   \n",
       "7267                    1                    0          1          0   \n",
       "\n",
       "      Binaryema50  Binaryema21  Binaryema15  Binaryema5  Prediction  \n",
       "14              0            0            0           0    0.597851  \n",
       "15              0            0            0           0    0.554832  \n",
       "16              0            0            0           1    0.554832  \n",
       "17              1            1            1           1    0.540372  \n",
       "18              1            1            1           1    0.490305  \n",
       "...           ...          ...          ...         ...         ...  \n",
       "7263            1            1            1           1    0.536587  \n",
       "7264            0            0            0           1    0.551489  \n",
       "7265            0            1            1           1    0.551489  \n",
       "7266            1            1            1           1    0.503589  \n",
       "7267            0            0            0           0    0.551489  \n",
       "\n",
       "[7254 rows x 179 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc59df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictDF.to_csv('predictions/StackingPrediction_LR_ABC_LDA_GBC_to_GBC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86198c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
