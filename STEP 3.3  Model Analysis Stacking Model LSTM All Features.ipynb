{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3d9790",
   "metadata": {},
   "source": [
    "# University of Michigan \n",
    "# Master of Applied Data Science\n",
    "### SIAD 699: Capstone\n",
    "Team: James Yoon (jamyoon), Mario Feliciano (felicma), and James Tuccori (jtuccori)\n",
    "\n",
    "Date: April 2023\n",
    "____\n",
    "# Social Media Sentiment & Predicting Trading Signals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4301658",
   "metadata": {},
   "source": [
    "##### In this notebook, we add financials indicatiors and basic binary increase or decreasing indicators as features. We then run all the 177 features with 25,503 data points through a stacking model taking the top 4 probablistic models GBC, LR, LDA, ADA, and feeding then to an LSTM model.   For our assessment we use a GPU enabled computer to allow us to process the Kerelas model faster.\n",
    "\n",
    "##### The output of the notebook is the prediction of the model for the 7,340 testing data points, which will be used in Step 5 back testing.  StackingPrediction_LR_ABC_LDA_GBC_to_LSTM.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709bba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from finta import TA\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14fea5",
   "metadata": {},
   "source": [
    "Add new features for the financial indifcators from finta library. Also importing the Traing Data below from Step 2. Creating an expotential smoothing to help reduce significant variance in the close data. Then creating binary indicators of the columns and financial features to use as new features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947dd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "Df_hourly_merge = pd.read_csv('assets/MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv')\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "Indicatordata = _exponential_smooth(Df_hourly_merge[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "Df_hourly_merge2 = pd.merge(Df_hourly_merge, Indicatordatafinal, left_index=True, right_index=True)\n",
    "\n",
    "Df_hourly_merge2 = Df_hourly_merge2.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binary(value):\n",
    "  if value > 0:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "       'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "       'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "       'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "       '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "for column in columns: \n",
    "    Df_hourly_merge2['Binary{}'.format(column)]  = (Df_hourly_merge2[column] - Df_hourly_merge2[column].shift(1)).apply(binary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca380c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25503"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Df_hourly_merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da43cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>2x_retweets_+_favorites</th>\n",
       "      <th>polarity</th>\n",
       "      <th>W1 Score</th>\n",
       "      <th>Bull_ratio</th>\n",
       "      <th>W Score With Bull Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>BinaryROC</th>\n",
       "      <th>BinaryOBV</th>\n",
       "      <th>Binary20 period CCI</th>\n",
       "      <th>Binary14 period EMV</th>\n",
       "      <th>BinaryVIm</th>\n",
       "      <th>BinaryVIp</th>\n",
       "      <th>Binaryema50</th>\n",
       "      <th>Binaryema21</th>\n",
       "      <th>Binaryema15</th>\n",
       "      <th>Binaryema5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.517857</td>\n",
       "      <td>1.276786</td>\n",
       "      <td>10592.354167</td>\n",
       "      <td>1652.068452</td>\n",
       "      <td>45.605159</td>\n",
       "      <td>9.071429</td>\n",
       "      <td>0.124241</td>\n",
       "      <td>0.264455</td>\n",
       "      <td>3.275000</td>\n",
       "      <td>0.866089</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.685230</td>\n",
       "      <td>0.479419</td>\n",
       "      <td>14341.610169</td>\n",
       "      <td>1852.799031</td>\n",
       "      <td>74.444302</td>\n",
       "      <td>3.644068</td>\n",
       "      <td>0.067950</td>\n",
       "      <td>0.097316</td>\n",
       "      <td>3.342105</td>\n",
       "      <td>0.325240</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.138107</td>\n",
       "      <td>0.670077</td>\n",
       "      <td>21769.074169</td>\n",
       "      <td>2449.731458</td>\n",
       "      <td>68.571009</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>0.120056</td>\n",
       "      <td>0.144203</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>0.882520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.916462</td>\n",
       "      <td>0.670762</td>\n",
       "      <td>36958.090909</td>\n",
       "      <td>2790.968059</td>\n",
       "      <td>100.500076</td>\n",
       "      <td>3.257985</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.110483</td>\n",
       "      <td>5.964286</td>\n",
       "      <td>0.658951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.339394</td>\n",
       "      <td>0.921212</td>\n",
       "      <td>13345.724242</td>\n",
       "      <td>3208.639394</td>\n",
       "      <td>66.105667</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>0.136780</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>4.607143</td>\n",
       "      <td>0.920041</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>5.783333</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>12129.000000</td>\n",
       "      <td>1975.276190</td>\n",
       "      <td>108.150291</td>\n",
       "      <td>7.102381</td>\n",
       "      <td>0.077630</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>3.022222</td>\n",
       "      <td>0.237728</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25499</th>\n",
       "      <td>3.011905</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>14180.595238</td>\n",
       "      <td>1765.121429</td>\n",
       "      <td>31.755382</td>\n",
       "      <td>3.797619</td>\n",
       "      <td>0.095683</td>\n",
       "      <td>0.135134</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>0.578073</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25500</th>\n",
       "      <td>14.400000</td>\n",
       "      <td>2.407143</td>\n",
       "      <td>16161.992857</td>\n",
       "      <td>2084.061905</td>\n",
       "      <td>182.260151</td>\n",
       "      <td>19.214286</td>\n",
       "      <td>0.082271</td>\n",
       "      <td>0.107210</td>\n",
       "      <td>3.648649</td>\n",
       "      <td>0.391172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25501</th>\n",
       "      <td>21.570806</td>\n",
       "      <td>3.270153</td>\n",
       "      <td>11254.296296</td>\n",
       "      <td>1814.954248</td>\n",
       "      <td>428.484448</td>\n",
       "      <td>28.111111</td>\n",
       "      <td>0.070485</td>\n",
       "      <td>0.165014</td>\n",
       "      <td>1.887324</td>\n",
       "      <td>0.311435</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25502</th>\n",
       "      <td>7.505967</td>\n",
       "      <td>0.878282</td>\n",
       "      <td>10556.818616</td>\n",
       "      <td>2143.973747</td>\n",
       "      <td>140.745063</td>\n",
       "      <td>9.262530</td>\n",
       "      <td>0.079407</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>3.945946</td>\n",
       "      <td>0.534052</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25503 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorites  retweets  number_of_followers    following  \\\n",
       "0       6.517857  1.276786         10592.354167  1652.068452   \n",
       "1       2.685230  0.479419         14341.610169  1852.799031   \n",
       "2       2.138107  0.670077         21769.074169  2449.731458   \n",
       "3       1.916462  0.670762         36958.090909  2790.968059   \n",
       "4       4.339394  0.921212         13345.724242  3208.639394   \n",
       "...          ...       ...                  ...          ...   \n",
       "25498   5.783333  0.659524         12129.000000  1975.276190   \n",
       "25499   3.011905  0.392857         14180.595238  1765.121429   \n",
       "25500  14.400000  2.407143         16161.992857  2084.061905   \n",
       "25501  21.570806  3.270153         11254.296296  1814.954248   \n",
       "25502   7.505967  0.878282         10556.818616  2143.973747   \n",
       "\n",
       "       followers_following_ratio  2x_retweets_+_favorites  polarity  W1 Score  \\\n",
       "0                      45.605159                 9.071429  0.124241  0.264455   \n",
       "1                      74.444302                 3.644068  0.067950  0.097316   \n",
       "2                      68.571009                 3.478261  0.120056  0.144203   \n",
       "3                     100.500076                 3.257985  0.143717  0.110483   \n",
       "4                      66.105667                 6.181818  0.136780  0.199699   \n",
       "...                          ...                      ...       ...       ...   \n",
       "25498                 108.150291                 7.102381  0.077630  0.078660   \n",
       "25499                  31.755382                 3.797619  0.095683  0.135134   \n",
       "25500                 182.260151                19.214286  0.082271  0.107210   \n",
       "25501                 428.484448                28.111111  0.070485  0.165014   \n",
       "25502                 140.745063                 9.262530  0.079407  0.135342   \n",
       "\n",
       "       Bull_ratio  W Score With Bull Ratio  ...  BinaryROC  BinaryOBV  \\\n",
       "0        3.275000                 0.866089  ...          0          0   \n",
       "1        3.342105                 0.325240  ...          0          0   \n",
       "2        6.120000                 0.882520  ...          0          0   \n",
       "3        5.964286                 0.658951  ...          0          0   \n",
       "4        4.607143                 0.920041  ...          0          0   \n",
       "...           ...                      ...  ...        ...        ...   \n",
       "25498    3.022222                 0.237728  ...          0          0   \n",
       "25499    4.277778                 0.578073  ...          0          0   \n",
       "25500    3.648649                 0.391172  ...          0          0   \n",
       "25501    1.887324                 0.311435  ...          0          1   \n",
       "25502    3.945946                 0.534052  ...          0          0   \n",
       "\n",
       "       Binary20 period CCI  Binary14 period EMV  BinaryVIm  BinaryVIp  \\\n",
       "0                        0                    0          0          0   \n",
       "1                        0                    0          0          0   \n",
       "2                        0                    0          0          0   \n",
       "3                        0                    0          0          0   \n",
       "4                        1                    0          0          0   \n",
       "...                    ...                  ...        ...        ...   \n",
       "25498                    1                    1          0          1   \n",
       "25499                    0                    1          0          1   \n",
       "25500                    0                    0          1          0   \n",
       "25501                    0                    0          1          0   \n",
       "25502                    0                    0          1          0   \n",
       "\n",
       "       Binaryema50  Binaryema21  Binaryema15  Binaryema5  \n",
       "0                0            0            0           0  \n",
       "1                1            1            1           1  \n",
       "2                0            0            0           0  \n",
       "3                0            0            0           0  \n",
       "4                0            0            0           0  \n",
       "...            ...          ...          ...         ...  \n",
       "25498            0            0            0           0  \n",
       "25499            0            0            0           0  \n",
       "25500            0            0            0           0  \n",
       "25501            1            1            1           1  \n",
       "25502            0            0            0           0  \n",
       "\n",
       "[25503 rows x 178 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_hourly_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8825a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['favorites', 'retweets', 'number_of_followers', 'following',\n",
       "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
       "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
       "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
       "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
       "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
       "       'JMJ_5HMoving_averages', 'Actual_Label',\n",
       "       'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
       "       'Mkt Sentiment', 'Crypto Sentiment',\n",
       "       'Historically Optimal SMA(s-t)', 'Historically Optimal SMA(l-t)',\n",
       "       'Historically Optimal WMA(s-t)', 'Historically Optimal WMA(l-t)',\n",
       "       'Historically Optimal EMA(s-t)', 'Historically Optimal EMA(l-t)',\n",
       "       'Twitter Hourly Favorites SMA(s-t)',\n",
       "       'Twitter Hourly Favorites SMA(l-t)',\n",
       "       'Twitter Hourly Favorites WMA(s-t)',\n",
       "       'Twitter Hourly Favorites WMA(l-t)',\n",
       "       'Twitter Hourly Favorites EMA(s-t)',\n",
       "       'Twitter Hourly Favorites EMA(l-t)',\n",
       "       'Twitter Hourly Retweets SMA(s-t)',\n",
       "       'Twitter Hourly Retweets SMA(l-t)',\n",
       "       'Twitter Hourly Retweets WMA(s-t)',\n",
       "       'Twitter Hourly Retweets WMA(l-t)',\n",
       "       'Twitter Hourly Retweets EMA(s-t)',\n",
       "       'Twitter Hourly Retweets EMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
       "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
       "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
       "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
       "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
       "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
       "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
       "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
       "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
       "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
       "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
       "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
       "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
       "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
       "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
       "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
       "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
       "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
       "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
       "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
       "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
       "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
       "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
       "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
       "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
       "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
       "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
       "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
       "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
       "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
       "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
       "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
       "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
       "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
       "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
       "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
       "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
       "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
       "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
       "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
       "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
       "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
       "       'Binaryema5'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_hourly_merge2.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06bc84",
   "metadata": {},
   "source": [
    "#### Identifying what exactly are the features and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b89263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = Df_hourly_merge2\n",
    "data = data.dropna()\n",
    "\n",
    "feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "X_JMJ = data[feature_names_JMJ]\n",
    "y_JMJ = data['Actual_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71371fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names_JMJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67103e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422b15bc",
   "metadata": {},
   "source": [
    "## BASE ESTIMATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526efe47",
   "metadata": {},
   "source": [
    "#### Setting up the model and the gridsearch parameters for the top 5 models as functions, to to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce48f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _LogisticRegression(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new model\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_lr = {\n",
    "                    'C': [0.01, 0.1, 1, 10, 100], \n",
    "                    \"penalty\":['l2'],\n",
    "                    'solver': ['lbfgs'],\n",
    "                    'max_iter':[1000]\n",
    "        \n",
    "                    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    lr_gs = GridSearchCV(lr, params_lr, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    lr_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    lr_best = lr_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(lr_gs.best_params_)\n",
    "    \n",
    "    prediction = lr_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return lr_best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aaaebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_AdaBoostClassifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new model\n",
    "    abc = AdaBoostClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_abc =  {\n",
    "                'n_estimators': [20, 50, 70, 100],\n",
    "                'learning_rate' : [0.001, 0.01, 0.1, 0.2]\n",
    "                }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    abc_gs = GridSearchCV(abc, params_abc, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    abc_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    abc_best = abc_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(abc_gs.best_params_)\n",
    "    \n",
    "    prediction = abc_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return abc_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d99641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _train_LDA(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Create a new model\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    \n",
    "    param_lda = {\n",
    "                'solver': ['svd', 'lsqr', 'eigen']\n",
    "                                  \n",
    "                 }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    lda_gs = GridSearchCV(lda, param_lda, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    lda_gs.fit(X_train, y_train)\n",
    "              \n",
    "    # Save best model\n",
    "    lda_best = lda_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(lda_gs.best_params_)\n",
    "    \n",
    "    prediction = lda_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return lda_best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4fe796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _GradientBoosingClassifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a new model\n",
    "    GBC = GradientBoostingClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_nnclf = {\n",
    "    \"loss\":[\"log_loss\"],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\":[3,5],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[0.5, 1.0],\n",
    "    \"n_estimators\":[100]\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    GBC_gs = GridSearchCV(GBC, params_nnclf, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    GBC_gs.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Save best model\n",
    "    GBC_best = GBC_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    print(GBC_gs.best_params_)\n",
    "    \n",
    "    prediction = GBC_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return GBC_best\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75264452",
   "metadata": {},
   "source": [
    "## FINAL MODEL SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a01d4",
   "metadata": {},
   "source": [
    "####  This code performs cross-validation stracking model of the Base Models and then pushing them to the final Model for training. .  Specifically we are taking the 25,503 training data points, and doing a timeseries cross valiation, by looking back 7(168 hours) every 1 day (24 hours), the taking the overall performance of the top 5 models and the Ensemble Model in the end as out. \n",
    "\n",
    "#### We use both Scikit-Lean models and Kerelas models in one consolidated model. We had to use a KerasClassifier as an adapter to allow us to integrate our LSTM model  and use it int he Stracking Modified as a final model.\n",
    "\n",
    "#### One challenge witt this method is that it takes 12 hours to train, and also it is not possible to save the model given the different library used. So predictions and evaluations have to be done in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11fdf156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2316 2317 2318] [2319 2320 2321 ... 4633 4634 4635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.35      0.42      1084\n",
      "         1.0       0.57      0.75      0.64      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.55      0.53      2317\n",
      "weighted avg       0.56      0.56      0.54      2317\n",
      "\n",
      "[[375 709]\n",
      " [310 923]]\n",
      "{'learning_rate': 0.01, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.56      0.54      1084\n",
      "         1.0       0.58      0.53      0.55      1233\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[612 472]\n",
      " [581 652]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 27 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.52480077 0.52480077        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.25      0.33      1084\n",
      "         1.0       0.53      0.75      0.62      1233\n",
      "\n",
      "    accuracy                           0.52      2317\n",
      "   macro avg       0.50      0.50      0.47      2317\n",
      "weighted avg       0.50      0.52      0.48      2317\n",
      "\n",
      "[[270 814]\n",
      " [306 927]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.42      0.47      1084\n",
      "         1.0       0.57      0.69      0.62      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.55      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[456 628]\n",
      " [388 845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.57      0.54      1084\n",
      "         1.0       0.59      0.55      0.57      1233\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[614 470]\n",
      " [559 674]]\n",
      "ABC Accuracy = 0.5455330168321105 , LDA Accuracy = 0.5166163141993958 , LR Accuracy = 0.5602071644367717 , GBC Accuracy = 0.5615019421665948 , LTSM Accuracy = 0.5558912386706949\n",
      " \n",
      "[   0    1    2 ... 4633 4634 4635] [4636 4637 4638 ... 6950 6951 6952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.33      0.42      1178\n",
      "         1.0       0.53      0.77      0.63      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.56      0.55      0.53      2317\n",
      "weighted avg       0.56      0.55      0.52      2317\n",
      "\n",
      "[[386 792]\n",
      " [257 882]]\n",
      "{'learning_rate': 0.01, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.47      0.53      1178\n",
      "         1.0       0.55      0.68      0.61      1139\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.58      0.57      0.57      2317\n",
      "weighted avg       0.58      0.57      0.57      2317\n",
      "\n",
      "[[553 625]\n",
      " [370 769]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.55004255 0.5476693         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.04      0.08      1178\n",
      "         1.0       0.50      0.98      0.66      1139\n",
      "\n",
      "    accuracy                           0.50      2317\n",
      "   macro avg       0.57      0.51      0.37      2317\n",
      "weighted avg       0.57      0.50      0.36      2317\n",
      "\n",
      "[[  48 1130]\n",
      " [  27 1112]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.30      0.40      1178\n",
      "         1.0       0.53      0.80      0.64      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.57      0.55      0.52      2317\n",
      "weighted avg       0.57      0.55      0.52      2317\n",
      "\n",
      "[[353 825]\n",
      " [223 916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.43      0.49      1178\n",
      "         1.0       0.53      0.67      0.59      1139\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[506 672]\n",
      " [376 763]]\n",
      "ABC Accuracy = 0.570565386275356 , LDA Accuracy = 0.5006473888649116 , LR Accuracy = 0.5472593871385412 , GBC Accuracy = 0.5476909797151489 , LTSM Accuracy = 0.5476909797151489\n",
      " \n",
      "[   0    1    2 ... 6950 6951 6952] [6953 6954 6955 ... 9267 9268 9269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.52      0.54      1144\n",
      "         1.0       0.57      0.63      0.60      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[590 554]\n",
      " [432 741]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.59      0.58      1144\n",
      "         1.0       0.58      0.55      0.57      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[675 469]\n",
      " [522 651]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 27 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.49876917 0.49920103        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.61      0.58      1144\n",
      "         1.0       0.58      0.53      0.56      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[695 449]\n",
      " [550 623]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.59      0.58      1144\n",
      "         1.0       0.58      0.56      0.57      1173\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[672 472]\n",
      " [520 653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.59      0.57      1144\n",
      "         1.0       0.57      0.53      0.55      1173\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[673 471]\n",
      " [555 618]]\n",
      "ABC Accuracy = 0.5722917565817868 , LDA Accuracy = 0.5688390159689254 , LR Accuracy = 0.5744497194648253 , GBC Accuracy = 0.5718601640051791 , LTSM Accuracy = 0.5571860164005179\n",
      " \n",
      "[   0    1    2 ... 9267 9268 9269] [ 9270  9271  9272 ... 11584 11585 11586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.54      1127\n",
      "         1.0       0.55      0.53      0.54      1190\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[623 504]\n",
      " [564 626]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.61      0.56      1127\n",
      "         1.0       0.57      0.48      0.52      1190\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[685 442]\n",
      " [613 577]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.52556634 0.52535059        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.53      0.53      1127\n",
      "         1.0       0.56      0.56      0.56      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[600 527]\n",
      " [524 666]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.52      0.53      1127\n",
      "         1.0       0.56      0.57      0.57      1190\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[588 539]\n",
      " [509 681]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.59      0.55      1127\n",
      "         1.0       0.56      0.50      0.53      1190\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[661 466]\n",
      " [596 594]]\n",
      "ABC Accuracy = 0.5446698316788952 , LDA Accuracy = 0.5463962019853259 , LR Accuracy = 0.5390591281829953 , GBC Accuracy = 0.5476909797151489 , LTSM Accuracy = 0.5416486836426413\n",
      " \n",
      "[    0     1     2 ... 11584 11585 11586] [11587 11588 11589 ... 13901 13902 13903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.58      0.56      1125\n",
      "         1.0       0.58      0.55      0.56      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[648 477]\n",
      " [542 650]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.65      0.59      1125\n",
      "         1.0       0.59      0.47      0.52      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.55      2317\n",
      "weighted avg       0.56      0.56      0.55      2317\n",
      "\n",
      "[[736 389]\n",
      " [637 555]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53525739 0.53534371        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.67      0.59      1125\n",
      "         1.0       0.58      0.42      0.49      1192\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[757 368]\n",
      " [691 501]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.55      0.56      1125\n",
      "         1.0       0.58      0.59      0.59      1192\n",
      "\n",
      "    accuracy                           0.57      2317\n",
      "   macro avg       0.57      0.57      0.57      2317\n",
      "weighted avg       0.57      0.57      0.57      2317\n",
      "\n",
      "[[621 504]\n",
      " [489 703]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.57      0.55      1125\n",
      "         1.0       0.57      0.54      0.56      1192\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[640 485]\n",
      " [544 648]]\n",
      "ABC Accuracy = 0.5571860164005179 , LDA Accuracy = 0.5429434613724644 , LR Accuracy = 0.5602071644367717 , GBC Accuracy = 0.5714285714285714 , LTSM Accuracy = 0.5558912386706949\n",
      " \n",
      "[    0     1     2 ... 13901 13902 13903] [13904 13905 13906 ... 16218 16219 16220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.48      0.51      1120\n",
      "         1.0       0.56      0.60      0.58      1197\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.54      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[543 577]\n",
      " [474 723]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.62      0.57      1120\n",
      "         1.0       0.57      0.46      0.51      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[699 421]\n",
      " [647 550]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.529921   0.52984908        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.57      0.55      1120\n",
      "         1.0       0.56      0.52      0.54      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.55      0.54      0.54      2317\n",
      "\n",
      "[[641 479]\n",
      " [579 618]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.44      0.49      1120\n",
      "         1.0       0.55      0.65      0.60      1197\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[497 623]\n",
      " [423 774]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.51      0.52      1120\n",
      "         1.0       0.55      0.56      0.56      1197\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[572 548]\n",
      " [524 673]]\n",
      "ABC Accuracy = 0.5390591281829953 , LDA Accuracy = 0.543375053949072 , LR Accuracy = 0.5463962019853259 , GBC Accuracy = 0.5485541648683643 , LTSM Accuracy = 0.5373327578765645\n",
      " \n",
      "[    0     1     2 ... 16218 16219 16220] [16221 16222 16223 ... 18535 18536 18537]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.84      0.62      1100\n",
      "         1.0       0.58      0.20      0.29      1217\n",
      "\n",
      "    accuracy                           0.50      2317\n",
      "   macro avg       0.53      0.52      0.46      2317\n",
      "weighted avg       0.54      0.50      0.45      2317\n",
      "\n",
      "[[927 173]\n",
      " [978 239]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.65      0.57      1100\n",
      "         1.0       0.57      0.43      0.49      1217\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.53      0.53      2317\n",
      "\n",
      "[[714 386]\n",
      " [698 519]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 66 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54466388 0.54491049        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.56      0.54      1100\n",
      "         1.0       0.57      0.53      0.55      1217\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[614 486]\n",
      " [575 642]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.42      0.46      1100\n",
      "         1.0       0.55      0.65      0.60      1217\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.53      2317\n",
      "weighted avg       0.54      0.54      0.53      2317\n",
      "\n",
      "[[460 640]\n",
      " [423 794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.51      0.51      1100\n",
      "         1.0       0.55      0.55      0.55      1217\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[566 534]\n",
      " [552 665]]\n",
      "ABC Accuracy = 0.5321536469572723 , LDA Accuracy = 0.542080276219249 , LR Accuracy = 0.5032369443245576 , GBC Accuracy = 0.5412170910660337 , LTSM Accuracy = 0.5312904618040569\n",
      " \n",
      "[    0     1     2 ... 18535 18536 18537] [18538 18539 18540 ... 20852 20853 20854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.52      0.52      1139\n",
      "         1.0       0.53      0.54      0.54      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[587 552]\n",
      " [543 635]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.58      0.55      1139\n",
      "         1.0       0.54      0.48      0.51      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[661 478]\n",
      " [608 570]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54957383 0.54984351        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.86      0.63      1139\n",
      "         1.0       0.56      0.18      0.27      1178\n",
      "\n",
      "    accuracy                           0.51      2317\n",
      "   macro avg       0.53      0.52      0.45      2317\n",
      "weighted avg       0.53      0.51      0.45      2317\n",
      "\n",
      "[[975 164]\n",
      " [967 211]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.43      0.48      1139\n",
      "         1.0       0.53      0.63      0.58      1178\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[492 647]\n",
      " [437 741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.46      0.48      1139\n",
      "         1.0       0.52      0.57      0.55      1178\n",
      "\n",
      "    accuracy                           0.52      2317\n",
      "   macro avg       0.52      0.52      0.52      2317\n",
      "weighted avg       0.52      0.52      0.52      2317\n",
      "\n",
      "[[522 617]\n",
      " [501 677]]\n",
      "ABC Accuracy = 0.5312904618040569 , LDA Accuracy = 0.5118687958567113 , LR Accuracy = 0.5274061286145878 , GBC Accuracy = 0.5321536469572723 , LTSM Accuracy = 0.5174794993526112\n",
      " \n",
      "[    0     1     2 ... 20852 20853 20854] [20855 20856 20857 ... 23169 23170 23171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.43      0.47      1151\n",
      "         1.0       0.53      0.62      0.57      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.52      2317\n",
      "weighted avg       0.53      0.53      0.52      2317\n",
      "\n",
      "[[495 656]\n",
      " [440 726]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.54      1151\n",
      "         1.0       0.53      0.50      0.51      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.53      2317\n",
      "weighted avg       0.53      0.53      0.53      2317\n",
      "\n",
      "[[637 514]\n",
      " [584 582]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 64 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54054184 0.54011029        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.87      0.64      1151\n",
      "         1.0       0.56      0.17      0.26      1166\n",
      "\n",
      "    accuracy                           0.52      2317\n",
      "   macro avg       0.53      0.52      0.45      2317\n",
      "weighted avg       0.53      0.52      0.45      2317\n",
      "\n",
      "[[1000  151]\n",
      " [ 972  194]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.35      0.43      1151\n",
      "         1.0       0.53      0.71      0.60      1166\n",
      "\n",
      "    accuracy                           0.53      2317\n",
      "   macro avg       0.53      0.53      0.51      2317\n",
      "weighted avg       0.53      0.53      0.52      2317\n",
      "\n",
      "[[405 746]\n",
      " [341 825]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.48      0.50      1151\n",
      "         1.0       0.52      0.57      0.55      1166\n",
      "\n",
      "    accuracy                           0.52      2317\n",
      "   macro avg       0.52      0.52      0.52      2317\n",
      "weighted avg       0.52      0.52      0.52      2317\n",
      "\n",
      "[[547 604]\n",
      " [499 667]]\n",
      "ABC Accuracy = 0.5261113508847648 , LDA Accuracy = 0.5153215364695727 , LR Accuracy = 0.5269745360379802 , GBC Accuracy = 0.5308588692274493 , LTSM Accuracy = 0.5239533880017264\n",
      " \n",
      "[    0     1     2 ... 23169 23170 23171] [23172 23173 23174 ... 25486 25487 25488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.57      0.57      1166\n",
      "         1.0       0.56      0.54      0.55      1151\n",
      "\n",
      "    accuracy                           0.56      2317\n",
      "   macro avg       0.56      0.56      0.56      2317\n",
      "weighted avg       0.56      0.56      0.56      2317\n",
      "\n",
      "[[669 497]\n",
      " [530 621]]\n",
      "{'learning_rate': 0.001, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.57      0.56      1166\n",
      "         1.0       0.55      0.53      0.54      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.55      2317\n",
      "weighted avg       0.55      0.55      0.55      2317\n",
      "\n",
      "[[662 504]\n",
      " [542 609]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 631, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 463, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 65 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53823458 0.53797562        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'svd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.46      0.51      1166\n",
      "         1.0       0.54      0.65      0.59      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.56      0.55      0.55      2317\n",
      "weighted avg       0.56      0.55      0.55      2317\n",
      "\n",
      "[[540 626]\n",
      " [408 743]]\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.43      0.49      1166\n",
      "         1.0       0.54      0.67      0.60      1151\n",
      "\n",
      "    accuracy                           0.55      2317\n",
      "   macro avg       0.55      0.55      0.54      2317\n",
      "weighted avg       0.55      0.55      0.54      2317\n",
      "\n",
      "[[500 666]\n",
      " [375 776]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.55      0.55      1166\n",
      "         1.0       0.54      0.53      0.53      1151\n",
      "\n",
      "    accuracy                           0.54      2317\n",
      "   macro avg       0.54      0.54      0.54      2317\n",
      "weighted avg       0.54      0.54      0.54      2317\n",
      "\n",
      "[[644 522]\n",
      " [542 609]]\n",
      "ABC Accuracy = 0.5485541648683643 , LDA Accuracy = 0.5537332757876564 , LR Accuracy = 0.5567544238239103 , GBC Accuracy = 0.5507121277514027 , LTSM Accuracy = 0.540785498489426\n",
      " \n",
      " \n",
      "ABC Accuracy = 0.546741476046612\n",
      "LDA Accuracy = 0.5341821320673285\n",
      "LR Accuracy = 0.5441950798446266\n",
      "GBC Accuracy = 0.5503668536901166\n",
      "LTSM Accuracy = 0.5409149762624084\n",
      " \n",
      "Wall time: 12h 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "LTSM_RESULTS = []\n",
    "abc_RESULTS = []\n",
    "lda_RESULTS = []\n",
    "lr_RESULTS =[]\n",
    "GBC_RESULTS = []\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_JMJ):\n",
    "    print(train_index, test_index)\n",
    "    \n",
    "    X_train, X_test = X_JMJ.iloc[train_index], X_JMJ.iloc[test_index]\n",
    "    y_train, y_test = y_JMJ.iloc[train_index], y_JMJ.iloc[test_index]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #Setting up the Base Estimators\n",
    "    lr_model = _LogisticRegression(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    abc_model = _train_AdaBoostClassifier(X_train_scaled, y_train,  X_test_scaled, y_test)\n",
    "    lda_model = _train_LDA(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    GBC_model = _GradientBoosingClassifier(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "    def get_lstm_model():\n",
    "        # Define the final estimator using TensorFlow\n",
    "        lstm_model = Sequential()\n",
    "        lstm_model.add(LSTM(128, return_sequences=True, input_shape=(181, 1)))\n",
    "        lstm_model.add(LSTM(128,dropout = 0.2))\n",
    "        lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "        optimizer = Adam(learning_rate = 0.001)\n",
    "        lstm_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return lstm_model\n",
    "\n",
    "    keras_clf = KerasClassifier(get_lstm_model,batch_size=32, epochs=10, verbose=0)#2,callbacks=[early_stop])\n",
    "\n",
    "    # Define the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('lr', lr_model),('abc', abc_model),('lda', lda_model), ('GBC',GBC_model)], \n",
    "        final_estimator=keras_clf,\n",
    "        cv=5,\n",
    "        passthrough=True,\n",
    "        stack_method='predict_proba'\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier on the training data\n",
    "    stacking_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = stacking_classifier.predict(X_test_scaled)\n",
    "    testy_pred = (y_pred >= 0.5).astype(int)\n",
    "    \n",
    "    abc_prediction = abc_model.predict(X_test_scaled)\n",
    "    lda_prediction = lda_model.predict(X_test_scaled)\n",
    "    lr_prediction = lr_model.predict(X_test_scaled)\n",
    "    GBC_prediction = GBC_model.predict(X_test_scaled)\n",
    "\n",
    "    \n",
    "    abc_accuracy = accuracy_score(y_test.values, abc_prediction)\n",
    "    lda_accuracy = accuracy_score(y_test.values, lda_prediction)\n",
    "    lr_accuracy = accuracy_score(y_test.values, lr_prediction)\n",
    "    GBC_accuracy = accuracy_score(y_test.values, GBC_prediction)\n",
    "    LTSMaccurary = accuracy_score (y_test, testy_pred)   \n",
    "   \n",
    "\n",
    "\n",
    "    abc_RESULTS.append(abc_accuracy)\n",
    "    lda_RESULTS.append(lda_accuracy)\n",
    "    lr_RESULTS.append(lr_accuracy)\n",
    "    GBC_RESULTS.append(GBC_accuracy)\n",
    "    LTSM_RESULTS.append(LTSMaccurary)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, testy_pred))\n",
    "    print(confusion_matrix(y_test, testy_pred))\n",
    "    \n",
    "    print('ABC Accuracy = ' + str(abc_accuracy),', LDA Accuracy = ' + str(lda_accuracy),', LR Accuracy = ' + str(lr_accuracy),', GBC Accuracy = ' + str(GBC_accuracy),', LTSM Accuracy = ' + str(LTSMaccurary))#,GBC_accuracy, ensemble_accuracy)    \n",
    "    print(' ')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "print(' ')\n",
    "print('ABC Accuracy = ' + str( sum(abc_RESULTS) / len(abc_RESULTS)))\n",
    "print('LDA Accuracy = ' + str( sum(lda_RESULTS) / len(lda_RESULTS)))\n",
    "print('LR Accuracy = ' + str( sum(lr_RESULTS) / len(lr_RESULTS)))\n",
    "print('GBC Accuracy = ' + str( sum(GBC_RESULTS) / len(GBC_RESULTS)))\n",
    "print('LSTM Accuracy = ' + str( sum(LTSM_RESULTS) / len(LTSM_RESULTS)))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65e739e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                           subsample=0.5))],\n",
       "                   final_estimator=KerasClassifier(batch_size=32, epochs=10, model=&lt;function get_lstm_model at 0x0000017AAAD09700&gt;, verbose=0),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;lr&#x27;,\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               (&#x27;abc&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               (&#x27;lda&#x27;, LinearDiscriminantAnalysis()),\n",
       "                               (&#x27;GBC&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                           subsample=0.5))],\n",
       "                   final_estimator=KerasClassifier(batch_size=32, epochs=10, model=&lt;function get_lstm_model at 0x0000017AAAD09700&gt;, verbose=0),\n",
       "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.001, n_estimators=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lda</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01, subsample=0.5)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function get_lstm_model at 0x0000017AAAD09700&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=10\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lr',\n",
       "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
       "                               ('abc',\n",
       "                                AdaBoostClassifier(learning_rate=0.001,\n",
       "                                                   n_estimators=20)),\n",
       "                               ('lda', LinearDiscriminantAnalysis()),\n",
       "                               ('GBC',\n",
       "                                GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                           subsample=0.5))],\n",
       "                   final_estimator=KerasClassifier(batch_size=32, epochs=10, model=<function get_lstm_model at 0x0000017AAAD09700>, verbose=0),\n",
       "                   passthrough=True, stack_method='predict_proba')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "585825d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(cv=5,\n",
      "                   estimators=[('lr',\n",
      "                                LogisticRegression(C=0.01, max_iter=1000)),\n",
      "                               ('abc',\n",
      "                                AdaBoostClassifier(learning_rate=0.001,\n",
      "                                                   n_estimators=20)),\n",
      "                               ('lda', LinearDiscriminantAnalysis()),\n",
      "                               ('GBC',\n",
      "                                GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                                           subsample=0.5))],\n",
      "                   final_estimator=KerasClassifier(batch_size=32, epochs=10, model=<function get_lstm_model at 0x0000017AAAD09700>, verbose=0),\n",
      "                   passthrough=True, stack_method='predict_proba')\n"
     ]
    }
   ],
   "source": [
    "print(stacking_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be14ad0",
   "metadata": {},
   "source": [
    "# TESTING RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4a398",
   "metadata": {},
   "source": [
    "### Testing with Whole Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a6a0f",
   "metadata": {},
   "source": [
    "#### Importing the 7,340 testing dat apoints, adding the same financial indicators, binary feautres, then testing the performance of our model on the unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7d9b5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.56      0.55      3625\n",
      "         1.0       0.55      0.53      0.54      3629\n",
      "\n",
      "    accuracy                           0.55      7254\n",
      "   macro avg       0.55      0.55      0.55      7254\n",
      "weighted avg       0.55      0.55      0.55      7254\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "\n",
    "    \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    predict_y=  stacking_classifier.predict(X_test_scaled)\n",
    "    PredictDF['Predicted_Label']= predict_y\n",
    "\n",
    "    print(classification_report(y_test, predict_y))   \n",
    "    \n",
    "    confusion_mc = confusion_matrix(PredictDF['Actual_Label'], PredictDF['Predicted_Label'])\n",
    "    df_cm = pd.DataFrame(confusion_mc, \n",
    "                         index = [i for i in range(0,2)], columns = [i for i in range(0,2)])\n",
    "\n",
    "\n",
    "    PredictDF['ValueActual'] =0\n",
    "    PredictDF['BTCValueActual'] =0\n",
    "    if PredictDF.loc[PredictDF.index[0],'Actual_Label']==0.0:\n",
    "        PredictDF.loc[PredictDF.index[0],'ValueActual']=1000\n",
    "    else:\n",
    "        PredictDF.loc[PredictDF.index[0],'BTCValueActual']=round((1000/PredictDF.loc[PredictDF.index[0],'Close']),5)\n",
    "\n",
    "\n",
    "    for current in range(1, len(PredictDF.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if PredictDF.loc[PredictDF.index[current],'Actual_Label']==0 and PredictDF.loc[PredictDF.index[previous],'BTCValueActual']==0:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual']=PredictDF.loc[PredictDF.index[previous],'ValueActual']\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Actual_Label']==1 and PredictDF.loc[PredictDF.index[previous],'ValueActual'] ==0 :\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual']= 0\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValueActual']=round(PredictDF.loc[PredictDF.index[previous],'BTCValueActual'],3)\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Actual_Label']==1:\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValueActual'] = round((PredictDF.loc[PredictDF.index[previous],'ValueActual']/PredictDF.loc[PredictDF.index[current],'Close']),5)\n",
    "        else:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValueActual'] = round((PredictDF.loc[PredictDF.index[previous],'BTCValueActual'] *PredictDF.loc[PredictDF.index[current],'Close']),3)\n",
    "\n",
    "\n",
    "    PredictDF['ValuePredicted'] =0\n",
    "    PredictDF['BTCValuePredicted'] =0\n",
    "    if PredictDF.loc[PredictDF.index[0],'Predicted_Label']==0.0:\n",
    "        PredictDF.loc[PredictDF.index[0],'ValuePredicted']=1000\n",
    "    else:\n",
    "        PredictDF.loc[PredictDF.index[0],'BTCValuePredicted']=round((1000/PredictDF.loc[PredictDF.index[0],'Close']),5)\n",
    "\n",
    "\n",
    "    for current in range(1, len(PredictDF.index)):\n",
    "        previous = current - 1\n",
    "\n",
    "        if PredictDF.loc[PredictDF.index[current],'Predicted_Label']==0 and PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted']==0:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted']=PredictDF.loc[PredictDF.index[previous],'ValuePredicted']\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Predicted_Label']==1 and PredictDF.loc[PredictDF.index[previous],'ValuePredicted'] ==0 :\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted']= 0\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValuePredicted']=round(PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted'],3)\n",
    "        elif PredictDF.loc[PredictDF.index[current],'Predicted_Label']==1:\n",
    "            PredictDF.loc[PredictDF.index[current],'BTCValuePredicted'] = round((PredictDF.loc[PredictDF.index[previous],'ValuePredicted']/PredictDF.loc[PredictDF.index[current],'Close']),5)\n",
    "        else:\n",
    "            PredictDF.loc[PredictDF.index[current],'ValuePredicted'] = round((PredictDF.loc[PredictDF.index[previous],'BTCValuePredicted'] *PredictDF.loc[PredictDF.index[current],'Close']),3)\n",
    "    df = PredictDF.mask(PredictDF==0).ffill().iloc[[-1]]\n",
    "    LastPredictvalue = df['ValuePredicted'].values[0]\n",
    "    LastPredictBTC = df['BTCValuePredicted'].values[0]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "    plt.title('Assessment for: {}\\nAccuracy:{:.3f}\\nPrecision:{:.3f}\\nRecall:{:.3f}\\nF1:{:.3f}\\nBenchmark USD Value and BTC  ${:,.2f} and {:,.2f}\\nPredicted USD Value and BTC ${:,.2f} and {:,.2f}'.format(x, accuracy_score(PredictDF['Actual_Label'],PredictDF['Predicted_Label']),\n",
    "                                                                        precision_score(PredictDF['Actual_Label'],PredictDF['Predicted_Label']),\n",
    "                                                                                    recall_score(PredictDF['Actual_Label'], PredictDF['Predicted_Label']),\n",
    "                                                                                    f1_score(PredictDF['Actual_Label'], PredictDF['Predicted_Label']),\n",
    "                                                                                     max(PredictDF['ValueActual']),max(PredictDF['BTCValueActual']),\n",
    "                                                                                     LastPredictvalue,LastPredictBTC\n",
    "                                                                                    ))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffcbfac",
   "metadata": {},
   "source": [
    "## Trying with Thesholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9941c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.02      0.04       769\n",
      "         1.0       0.57      0.99      0.72      1013\n",
      "\n",
      "    accuracy                           0.57      1782\n",
      "   macro avg       0.61      0.51      0.38      1782\n",
      "weighted avg       0.60      0.57      0.43      1782\n",
      "\n",
      "[[  16  753]\n",
      " [   9 1004]]\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.55\n",
    "LowerThresshold = 0.45\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "\n",
    "    \n",
    "    \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    predict_y=  stacking_classifier.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "    testy_predThreshold = np.where(predict_y > UpperThreshold, 1,np.where(predict_y < LowerThresshold, 0,2))\n",
    "    testy_predThreshold = testy_predThreshold.squeeze()\n",
    "    dataset = pd.DataFrame({'Y_TEST': y_test, 'Y_PREDICTED': testy_predThreshold}, columns=['Y_TEST', 'Y_PREDICTED'])\n",
    "    dataset2 = dataset.drop(dataset[dataset.Y_PREDICTED == 2].index)\n",
    "   \n",
    "    try:\n",
    "\n",
    "        print(classification_report(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "        print(confusion_matrix(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "    except:\n",
    "        print(\"No values\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ad7d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No values\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.6\n",
    "LowerThresshold = 0.4\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "   \n",
    "    \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    predict_y=  stacking_classifier.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "\n",
    "    testy_predThreshold = np.where(predict_y > UpperThreshold, 1,np.where(predict_y < LowerThresshold, 0,2))\n",
    "    testy_predThreshold = testy_predThreshold.squeeze()\n",
    "    dataset = pd.DataFrame({'Y_TEST': y_test, 'Y_PREDICTED': testy_predThreshold}, columns=['Y_TEST', 'Y_PREDICTED'])\n",
    "    dataset2 = dataset.drop(dataset[dataset.Y_PREDICTED == 2].index)\n",
    "   \n",
    "    try:\n",
    "        print(classification_report(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "        print(confusion_matrix(dataset2['Y_TEST'].values, dataset2['Y_PREDICTED'].values))\n",
    "    except:\n",
    "        print(\"No values\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bd280",
   "metadata": {},
   "source": [
    "### Exporting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcdf0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']\n",
    "\n",
    "testdata2022 ='assets/TEST_MergeJMJPCHourly2019202_NewsGoogleApi_ActualLabel.csv'\n",
    "\n",
    "files= [testdata2022]\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['Close'] / data['Close'].ewm(50).mean()\n",
    "    data['ema21'] = data['Close'] / data['Close'].ewm(21).mean()\n",
    "    data['ema15'] = data['Close'] / data['Close'].ewm(14).mean()\n",
    "    data['ema5'] = data['Close'] / data['Close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['Volume'] / data['Volume'].ewm(5).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "UpperThreshold = 0.5\n",
    "LowerThresshold = 0.5\n",
    "\n",
    "for file,x in zip(files, ['testdata2022']):\n",
    "    PredictDF= pd.read_csv(file)\n",
    "    prediction = (PredictDF.shift(-1)['Close'] >= PredictDF['Close'])\n",
    "    prediction = prediction.iloc[:-1]\n",
    "    PredictDF['Actual_Label'] = prediction.astype(int)\n",
    "    PredictDF= PredictDF.dropna()\n",
    "    \n",
    "    Indicatordata = _exponential_smooth(PredictDF[['Close', 'Open','High','Low','Volume']], 0.65)\n",
    "\n",
    "    Indicatordatafinal = _get_indicator_data(Indicatordata)\n",
    "\n",
    "    Indicatordatafinal = Indicatordatafinal.drop(['Close', 'Open', 'High', 'Low', 'Volume'], axis = 1)\n",
    "    PredictDF = pd.merge(PredictDF, Indicatordatafinal, left_index=True, right_index=True)\n",
    "    PredictDF = PredictDF.drop(['time','hour','Open Time','_merge','Signal','Position', 'Signal35JMJ', 'Position35JMJ', 'Ignore'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    columns = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "           'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "           'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open', 'High',\n",
    "           'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades',\n",
    "           'TB Base Volume', 'TB Quote Volume', '3MovingAverage', '5MovingAverage',\n",
    "           'JMJ_3HMoving_averages', 'JMJ_5HMoving_averages', \n",
    "           '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "           '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV', '20 period CCI',\n",
    "           '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21', 'ema15', 'ema5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        PredictDF['Binary{}'.format(column)]  = (PredictDF[column] - PredictDF[column].shift(1)).apply(binary)\n",
    "    \n",
    "\n",
    "    PredictDF = PredictDF.dropna()\n",
    "   \n",
    "    feature_names_JMJ = ['favorites', 'retweets', 'number_of_followers', 'following',\n",
    "       'followers_following_ratio', '2x_retweets_+_favorites', 'polarity',\n",
    "       'W1 Score', 'Bull_ratio', 'W Score With Bull Ratio', 'Open',\n",
    "       'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "       'Number of Trades', 'TB Base Volume', 'TB Quote Volume',\n",
    "       '3MovingAverage', '5MovingAverage', 'JMJ_3HMoving_averages',\n",
    "        'Bitcoin_Google_Trend_Score', 'BTC_Google_Trend_Score',\n",
    "       'JMJ_5HMoving_averages', 'Mkt Sentiment',\n",
    "       'Crypto Sentiment', 'Historically Optimal SMA(s-t)',\n",
    "       'Historically Optimal SMA(l-t)', 'Historically Optimal WMA(s-t)',\n",
    "       'Historically Optimal WMA(l-t)', 'Historically Optimal EMA(s-t)',\n",
    "       'Historically Optimal EMA(l-t)',\n",
    "       'Twitter Hourly Favorites SMA(s-t)',\n",
    "       'Twitter Hourly Favorites SMA(l-t)',\n",
    "       'Twitter Hourly Favorites WMA(s-t)',\n",
    "       'Twitter Hourly Favorites WMA(l-t)',\n",
    "       'Twitter Hourly Favorites EMA(s-t)',\n",
    "       'Twitter Hourly Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Retweets SMA(s-t)',\n",
    "       'Twitter Hourly Retweets SMA(l-t)',\n",
    "       'Twitter Hourly Retweets WMA(s-t)',\n",
    "       'Twitter Hourly Retweets WMA(l-t)',\n",
    "       'Twitter Hourly Retweets EMA(s-t)',\n",
    "       'Twitter Hourly Retweets EMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Follower Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure SMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure WMA(l-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(s-t)',\n",
    "       'Twitter Hourly Following Exposure EMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Follower to Following Ratio EMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites SMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites WMA(l-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(s-t)',\n",
    "       'Twitter Hourly 2x Retweets + Favorites EMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score SMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score WMA(l-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(s-t)',\n",
    "       'Twitter Hourly Polarity Score EMA(l-t)',\n",
    "       'Twitter W1 Score SMA(s-t)', 'Twitter W1 Score SMA(l-t)',\n",
    "       'Twitter W1 Score WMA(s-t)', 'Twitter W1 Score WMA(l-t)',\n",
    "       'Twitter W1 Score EMA(s-t)', 'Twitter W1 Score EMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Bull Ratio EMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio SMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio WMA(l-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(s-t)',\n",
    "       'Twitter Hourly Weighted Bull Ratio EMA(l-t)',\n",
    "       'Quote Asset Volume SMA(s-t)', 'Quote Asset Volume SMA(l-t)',\n",
    "       'Quote Asset Volume WMA(s-t)', 'Quote Asset Volume WMA(l-t)',\n",
    "       'Quote Asset Volume EMA(s-t)', 'Quote Asset Volume EMA(l-t)',\n",
    "       '# of Hourly Trades SMA(s-t)', '# of Hourly Trades SMA(l-t)',\n",
    "       '# of Hourly Trades WMA(s-t)', '# of Hourly Trades WMA(l-t)',\n",
    "       '# of Hourly Trades EMA(s-t)', '# of Hourly Trades EMA(l-t)',\n",
    "       'TB Base Volume SMA(s-t)', 'TB Base Volume SMA(l-t)',\n",
    "       'TB Base Volume WMA(s-t)', 'TB Base Volume WMA(l-t)',\n",
    "       'TB Base Volume EMA(s-t)', 'TB Base Volume EMA(l-t)',\n",
    "       'TB Quote Volume SMA(s-t)', 'TB Quote Volume SMA(l-t)',\n",
    "       'TB Quote Volume WMA(s-t)', 'TB Quote Volume WMA(l-t)',\n",
    "       'TB Quote Volume EMA(s-t)', 'TB Quote Volume EMA(l-t)',\n",
    "       '14 period RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
    "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV',\n",
    "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
    "       'ema15', 'ema5', 'normVol', 'Binaryfavorites', 'Binaryretweets',\n",
    "       'Binarynumber_of_followers', 'Binaryfollowing',\n",
    "       'Binaryfollowers_following_ratio', 'Binary2x_retweets_+_favorites',\n",
    "       'Binarypolarity', 'BinaryW1 Score', 'BinaryBull_ratio',\n",
    "       'BinaryW Score With Bull Ratio', 'BinaryOpen', 'BinaryHigh',\n",
    "       'BinaryLow', 'BinaryClose', 'BinaryVolume',\n",
    "       'BinaryQuote Asset Volume', 'BinaryNumber of Trades',\n",
    "       'BinaryTB Base Volume', 'BinaryTB Quote Volume',\n",
    "       'Binary3MovingAverage', 'Binary5MovingAverage',\n",
    "       'BinaryJMJ_3HMoving_averages', 'BinaryJMJ_5HMoving_averages',\n",
    "       'Binary14 period RSI', 'BinaryMACD', 'BinarySIGNAL',\n",
    "       'Binary14 period STOCH %K', 'BinaryMFV', 'Binary14 period ATR',\n",
    "       'BinaryMOM', 'Binary14 period MFI', 'BinaryROC', 'BinaryOBV',\n",
    "       'Binary20 period CCI', 'Binary14 period EMV', 'BinaryVIm',\n",
    "       'BinaryVIp', 'Binaryema50', 'Binaryema21', 'Binaryema15',\n",
    "       'Binaryema5']\n",
    "\n",
    "\n",
    "    X_test = PredictDF[feature_names_JMJ]\n",
    "    y_test = PredictDF['Actual_Label']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    PredictDF['Prediction'] = stacking_classifier.predict_proba(X_test_scaled)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c00dcbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>2x_retweets_+_favorites</th>\n",
       "      <th>polarity</th>\n",
       "      <th>W1 Score</th>\n",
       "      <th>Bull_ratio</th>\n",
       "      <th>W Score With Bull Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>BinaryOBV</th>\n",
       "      <th>Binary20 period CCI</th>\n",
       "      <th>Binary14 period EMV</th>\n",
       "      <th>BinaryVIm</th>\n",
       "      <th>BinaryVIp</th>\n",
       "      <th>Binaryema50</th>\n",
       "      <th>Binaryema21</th>\n",
       "      <th>Binaryema15</th>\n",
       "      <th>Binaryema5</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.797619</td>\n",
       "      <td>0.745238</td>\n",
       "      <td>16514.150000</td>\n",
       "      <td>1498.323810</td>\n",
       "      <td>63.299076</td>\n",
       "      <td>11.288095</td>\n",
       "      <td>0.113520</td>\n",
       "      <td>0.128081</td>\n",
       "      <td>4.256410</td>\n",
       "      <td>0.545164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39.326190</td>\n",
       "      <td>3.390476</td>\n",
       "      <td>16099.623810</td>\n",
       "      <td>1672.185714</td>\n",
       "      <td>110.504489</td>\n",
       "      <td>46.107143</td>\n",
       "      <td>0.087327</td>\n",
       "      <td>0.253405</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.369048</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11057.442857</td>\n",
       "      <td>1828.021429</td>\n",
       "      <td>133.780075</td>\n",
       "      <td>6.469048</td>\n",
       "      <td>0.093584</td>\n",
       "      <td>0.222649</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>0.545491</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.495238</td>\n",
       "      <td>1.890476</td>\n",
       "      <td>25029.171429</td>\n",
       "      <td>1882.980952</td>\n",
       "      <td>662.631886</td>\n",
       "      <td>18.276190</td>\n",
       "      <td>0.090903</td>\n",
       "      <td>0.173174</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.432936</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.329545</td>\n",
       "      <td>1.281818</td>\n",
       "      <td>22107.427273</td>\n",
       "      <td>2018.227273</td>\n",
       "      <td>479.791704</td>\n",
       "      <td>15.893182</td>\n",
       "      <td>0.095774</td>\n",
       "      <td>0.263250</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>0.893952</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>10.030952</td>\n",
       "      <td>2.557143</td>\n",
       "      <td>12561.900000</td>\n",
       "      <td>906.071429</td>\n",
       "      <td>406.088057</td>\n",
       "      <td>15.145238</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.365355</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>1.120422</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>9.507143</td>\n",
       "      <td>3.530952</td>\n",
       "      <td>10695.850000</td>\n",
       "      <td>805.514286</td>\n",
       "      <td>264.229345</td>\n",
       "      <td>16.569048</td>\n",
       "      <td>0.075146</td>\n",
       "      <td>0.250643</td>\n",
       "      <td>2.518519</td>\n",
       "      <td>0.631248</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.402381</td>\n",
       "      <td>22596.990476</td>\n",
       "      <td>846.535714</td>\n",
       "      <td>217.348828</td>\n",
       "      <td>26.761905</td>\n",
       "      <td>0.104180</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>1.187930</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>4.788095</td>\n",
       "      <td>1.021429</td>\n",
       "      <td>21378.707143</td>\n",
       "      <td>730.971429</td>\n",
       "      <td>172.471290</td>\n",
       "      <td>6.830952</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.310215</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>1.295602</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>10.600000</td>\n",
       "      <td>1.764286</td>\n",
       "      <td>15495.466667</td>\n",
       "      <td>663.738095</td>\n",
       "      <td>170.085989</td>\n",
       "      <td>14.128571</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>0.206627</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.671536</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7254 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      favorites  retweets  number_of_followers    following  \\\n",
       "14     9.797619  0.745238         16514.150000  1498.323810   \n",
       "15    39.326190  3.390476         16099.623810  1672.185714   \n",
       "16     5.369048  0.550000         11057.442857  1828.021429   \n",
       "17    14.495238  1.890476         25029.171429  1882.980952   \n",
       "18    13.329545  1.281818         22107.427273  2018.227273   \n",
       "...         ...       ...                  ...          ...   \n",
       "7263  10.030952  2.557143         12561.900000   906.071429   \n",
       "7264   9.507143  3.530952         10695.850000   805.514286   \n",
       "7265  17.957143  4.402381         22596.990476   846.535714   \n",
       "7266   4.788095  1.021429         21378.707143   730.971429   \n",
       "7267  10.600000  1.764286         15495.466667   663.738095   \n",
       "\n",
       "      followers_following_ratio  2x_retweets_+_favorites  polarity  W1 Score  \\\n",
       "14                    63.299076                11.288095  0.113520  0.128081   \n",
       "15                   110.504489                46.107143  0.087327  0.253405   \n",
       "16                   133.780075                 6.469048  0.093584  0.222649   \n",
       "17                   662.631886                18.276190  0.090903  0.173174   \n",
       "18                   479.791704                15.893182  0.095774  0.263250   \n",
       "...                         ...                      ...       ...       ...   \n",
       "7263                 406.088057                15.145238  0.094200  0.365355   \n",
       "7264                 264.229345                16.569048  0.075146  0.250643   \n",
       "7265                 217.348828                26.761905  0.104180  0.403896   \n",
       "7266                 172.471290                 6.830952  0.097456  0.310215   \n",
       "7267                 170.085989                14.128571  0.078864  0.206627   \n",
       "\n",
       "      Bull_ratio  W Score With Bull Ratio  ...  BinaryOBV  \\\n",
       "14      4.256410                 0.545164  ...          0   \n",
       "15      2.500000                 0.633513  ...          0   \n",
       "16      2.450000                 0.545491  ...          0   \n",
       "17      2.500000                 0.432936  ...          1   \n",
       "18      3.395833                 0.893952  ...          1   \n",
       "...          ...                      ...  ...        ...   \n",
       "7263    3.066667                 1.120422  ...          1   \n",
       "7264    2.518519                 0.631248  ...          0   \n",
       "7265    2.941176                 1.187930  ...          0   \n",
       "7266    4.176471                 1.295602  ...          1   \n",
       "7267    3.250000                 0.671536  ...          0   \n",
       "\n",
       "      Binary20 period CCI  Binary14 period EMV  BinaryVIm  BinaryVIp  \\\n",
       "14                      1                    0          0          0   \n",
       "15                      0                    0          1          0   \n",
       "16                      1                    0          1          0   \n",
       "17                      1                    1          0          1   \n",
       "18                      1                    1          0          1   \n",
       "...                   ...                  ...        ...        ...   \n",
       "7263                    1                    1          0          1   \n",
       "7264                    1                    1          0          1   \n",
       "7265                    0                    0          1          1   \n",
       "7266                    1                    0          1          0   \n",
       "7267                    1                    0          1          0   \n",
       "\n",
       "      Binaryema50  Binaryema21  Binaryema15  Binaryema5  Prediction  \n",
       "14              0            0            0           0    0.576984  \n",
       "15              0            0            0           0    0.558649  \n",
       "16              0            0            0           1    0.556702  \n",
       "17              1            1            1           1    0.468112  \n",
       "18              1            1            1           1    0.456642  \n",
       "...           ...          ...          ...         ...         ...  \n",
       "7263            1            1            1           1    0.480943  \n",
       "7264            0            0            0           1    0.514958  \n",
       "7265            0            1            1           1    0.519998  \n",
       "7266            1            1            1           1    0.460276  \n",
       "7267            0            0            0           0    0.553227  \n",
       "\n",
       "[7254 rows x 179 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb93f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictDF.to_csv('predictions/StackingPrediction_LR_ABC_LDA_GBC_to_LSTM.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
